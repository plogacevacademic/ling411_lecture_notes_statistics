<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Error-less Linear Models | Statistics in R</title>
  <meta name="description" content="Chapter 4 Error-less Linear Models | Statistics in R" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Error-less Linear Models | Statistics in R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Error-less Linear Models | Statistics in R" />
  
  
  

<meta name="author" content="Pavel Logacev" />


<meta name="date" content="2021-11-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="descriptives.html"/>
<link rel="next" href="lms_with_error.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.19/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<script src="libs/rglWebGL-binding-0.107.14/rglWebGL.js"></script>
<link href="libs/rglwidgetClass-0.107.14/rgl.css" rel="stylesheet" />
<script src="libs/rglwidgetClass-0.107.14/rglClass.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/utils.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/subscenes.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/shaders.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/textures.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/projection.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/mouse.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/init.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/pieces.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/draw.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/controls.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/selection.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/rglTimer.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/pretty.src.js"></script>
<script src="libs/rglwidgetClass-0.107.14/axes.src.js"></script>
<script src="libs/CanvasMatrix4-0.107.14/CanvasMatrix.src.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Initial Remarks</a></li>
<li class="chapter" data-level="2" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html"><i class="fa fa-check"></i><b>2</b> Scales of Measurement</a><ul>
<li class="chapter" data-level="2.1" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#nominal-scale"><i class="fa fa-check"></i><b>2.1</b> Nominal scale</a></li>
<li class="chapter" data-level="2.2" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#ordinal-scale"><i class="fa fa-check"></i><b>2.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="2.3" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#interval-scale"><i class="fa fa-check"></i><b>2.3</b> Interval scale</a></li>
<li class="chapter" data-level="2.4" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#ratio-scale"><i class="fa fa-check"></i><b>2.4</b> Ratio scale</a></li>
<li class="chapter" data-level="2.5" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#continuous-versus-discrete-variables"><i class="fa fa-check"></i><b>2.5</b> Continuous versus discrete variables</a></li>
<li class="chapter" data-level="2.6" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#some-complexities"><i class="fa fa-check"></i><b>2.6</b> Some complexities</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>3</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="3.1" data-path="descriptives.html"><a href="descriptives.html#centraltendency"><i class="fa fa-check"></i><b>3.1</b> Measures of central tendency</a><ul>
<li class="chapter" data-level="3.1.1" data-path="descriptives.html"><a href="descriptives.html#mean"><i class="fa fa-check"></i><b>3.1.1</b> The mean</a></li>
<li class="chapter" data-level="3.1.2" data-path="descriptives.html"><a href="descriptives.html#calculating-the-mean-in-r"><i class="fa fa-check"></i><b>3.1.2</b> Calculating the mean in R</a></li>
<li class="chapter" data-level="3.1.3" data-path="descriptives.html"><a href="descriptives.html#median"><i class="fa fa-check"></i><b>3.1.3</b> The median</a></li>
<li class="chapter" data-level="3.1.4" data-path="descriptives.html"><a href="descriptives.html#mean-or-median-whats-the-difference"><i class="fa fa-check"></i><b>3.1.4</b> Mean or median? What’s the difference?</a></li>
<li class="chapter" data-level="3.1.5" data-path="descriptives.html"><a href="descriptives.html#trimmedmean"><i class="fa fa-check"></i><b>3.1.5</b> Trimmed mean</a></li>
<li class="chapter" data-level="3.1.6" data-path="descriptives.html"><a href="descriptives.html#mode"><i class="fa fa-check"></i><b>3.1.6</b> Mode</a></li>
<li class="chapter" data-level="3.1.7" data-path="descriptives.html"><a href="descriptives.html#summary"><i class="fa fa-check"></i><b>3.1.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="descriptives.html"><a href="descriptives.html#var"><i class="fa fa-check"></i><b>3.2</b> Measures of variability</a><ul>
<li class="chapter" data-level="3.2.1" data-path="descriptives.html"><a href="descriptives.html#range"><i class="fa fa-check"></i><b>3.2.1</b> Range</a></li>
<li class="chapter" data-level="3.2.2" data-path="descriptives.html"><a href="descriptives.html#quantiles-and-percentile"><i class="fa fa-check"></i><b>3.2.2</b> Quantiles and percentile</a></li>
<li class="chapter" data-level="3.2.3" data-path="descriptives.html"><a href="descriptives.html#interquartile-range"><i class="fa fa-check"></i><b>3.2.3</b> Interquartile range</a></li>
<li class="chapter" data-level="3.2.4" data-path="descriptives.html"><a href="descriptives.html#aad"><i class="fa fa-check"></i><b>3.2.4</b> Mean absolute deviation</a></li>
<li class="chapter" data-level="3.2.5" data-path="descriptives.html"><a href="descriptives.html#variance"><i class="fa fa-check"></i><b>3.2.5</b> Variance</a></li>
<li class="chapter" data-level="3.2.6" data-path="descriptives.html"><a href="descriptives.html#sd"><i class="fa fa-check"></i><b>3.2.6</b> Standard deviation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="errorless_lms.html"><a href="errorless_lms.html"><i class="fa fa-check"></i><b>4</b> Error-less Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="errorless_lms.html"><a href="errorless_lms.html#single-variable-models"><i class="fa fa-check"></i><b>4.1</b> Single-variable models</a></li>
<li class="chapter" data-level="4.2" data-path="errorless_lms.html"><a href="errorless_lms.html#multi-variable-models"><i class="fa fa-check"></i><b>4.2</b> Multi-variable models</a></li>
<li class="chapter" data-level="4.3" data-path="errorless_lms.html"><a href="errorless_lms.html#models-with-categorical-predictors"><i class="fa fa-check"></i><b>4.3</b> Models with categorical predictors</a></li>
<li class="chapter" data-level="4.4" data-path="errorless_lms.html"><a href="errorless_lms.html#centered-predictors"><i class="fa fa-check"></i><b>4.4</b> Centered predictors</a></li>
<li class="chapter" data-level="4.5" data-path="errorless_lms.html"><a href="errorless_lms.html#main-effects-and-interactions"><i class="fa fa-check"></i><b>4.5</b> Main effects and interactions</a></li>
<li class="chapter" data-level="4.6" data-path="errorless_lms.html"><a href="errorless_lms.html#centered-predictors-and-their-effect-on-main-effect-and-interaction-coefficients"><i class="fa fa-check"></i><b>4.6</b> Centered predictors and their effect on main effect and interaction coefficients</a><ul>
<li class="chapter" data-level="4.6.1" data-path="errorless_lms.html"><a href="errorless_lms.html#treatment-contrasts"><i class="fa fa-check"></i><b>4.6.1</b> Treatment Contrasts</a></li>
<li class="chapter" data-level="4.6.2" data-path="errorless_lms.html"><a href="errorless_lms.html#centered-contrasts-aka-sum-contrasts"><i class="fa fa-check"></i><b>4.6.2</b> Centered Contrasts (aka Sum Contrasts)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lms_with_error.html"><a href="lms_with_error.html"><i class="fa fa-check"></i><b>5</b> Linear Models With Error</a><ul>
<li class="chapter" data-level="5.1" data-path="lms_with_error.html"><a href="lms_with_error.html#a-whole-zoo-of-models"><i class="fa fa-check"></i><b>5.1</b> A Whole Zoo of Models</a></li>
<li class="chapter" data-level="5.2" data-path="lms_with_error.html"><a href="lms_with_error.html#an-updated-linear-model"><i class="fa fa-check"></i><b>5.2</b> An Updated Linear Model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="examples.html"><a href="examples.html"><i class="fa fa-check"></i><b>6</b> Examples</a><ul>
<li class="chapter" data-level="6.1" data-path="examples.html"><a href="examples.html#the-dative-verbs-data"><i class="fa fa-check"></i><b>6.1</b> The Dative Verbs Data</a><ul>
<li class="chapter" data-level="6.1.1" data-path="examples.html"><a href="examples.html#by-length-of-recipient"><i class="fa fa-check"></i><b>6.1.1</b> By Length of Recipient</a></li>
<li class="chapter" data-level="6.1.2" data-path="examples.html"><a href="examples.html#by-length-of-theme"><i class="fa fa-check"></i><b>6.1.2</b> By Length of Theme</a></li>
<li class="chapter" data-level="6.1.3" data-path="examples.html"><a href="examples.html#by-length-of-recipient-and-length-of-theme"><i class="fa fa-check"></i><b>6.1.3</b> By Length of Recipient and Length of Theme</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html"><i class="fa fa-check"></i><b>7</b> Samples, Populations and Probability</a><ul>
<li class="chapter" data-level="7.1" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#the-dative-verbs-data-revisited"><i class="fa fa-check"></i><b>7.1</b> The Dative Verbs Data Revisited</a></li>
<li class="chapter" data-level="7.2" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#populations-and-samples"><i class="fa fa-check"></i><b>7.2</b> Populations and Samples</a><ul>
<li class="chapter" data-level="7.2.1" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#examples-1"><i class="fa fa-check"></i><b>7.2.1</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#the-role-of-statistical-models"><i class="fa fa-check"></i><b>7.3</b> The Role of Statistical Models</a></li>
<li class="chapter" data-level="7.4" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#probability"><i class="fa fa-check"></i><b>7.4</b> Probability</a><ul>
<li class="chapter" data-level="7.4.1" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#examples-of-probabilistic-statments"><i class="fa fa-check"></i><b>7.4.1</b> Examples of Probabilistic Statments</a></li>
<li class="chapter" data-level="7.4.2" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#the-notion-of-probability"><i class="fa fa-check"></i><b>7.4.2</b> The Notion of Probability</a></li>
<li class="chapter" data-level="7.4.3" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#the-laws-of-probability"><i class="fa fa-check"></i><b>7.4.3</b> The Laws of Probability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="statistical-models.html"><a href="statistical-models.html"><i class="fa fa-check"></i><b>8</b> Statistical Models</a><ul>
<li class="chapter" data-level="8.0.1" data-path="statistical-models.html"><a href="statistical-models.html#a-first-statistical-model"><i class="fa fa-check"></i><b>8.0.1</b> A First Statistical Model</a></li>
<li class="chapter" data-level="8.1" data-path="statistical-models.html"><a href="statistical-models.html#log-likelihood-and-numerical-underflow"><i class="fa fa-check"></i><b>8.1</b> Log-likelihood and numerical underflow</a><ul>
<li class="chapter" data-level="8.1.1" data-path="statistical-models.html"><a href="statistical-models.html#logarithm"><i class="fa fa-check"></i><b>8.1.1</b> Logarithm</a></li>
<li class="chapter" data-level="8.1.2" data-path="statistical-models.html"><a href="statistical-models.html#log-likelihood"><i class="fa fa-check"></i><b>8.1.2</b> Log-likelihood</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html"><i class="fa fa-check"></i><b>9</b> Statistical Models II</a><ul>
<li class="chapter" data-level="9.0.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#example-1"><i class="fa fa-check"></i><b>9.0.1</b> Example 1</a></li>
<li class="chapter" data-level="9.0.2" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#example-2"><i class="fa fa-check"></i><b>9.0.2</b> Example 2</a></li>
<li class="chapter" data-level="9.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#probability-distributions"><i class="fa fa-check"></i><b>9.1</b> Probability Distributions</a><ul>
<li class="chapter" data-level="9.1.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#bernoulli-distribution"><i class="fa fa-check"></i><b>9.1.1</b> Bernoulli Distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#binomial-distribution"><i class="fa fa-check"></i><b>9.2</b> Binomial Distribution</a><ul>
<li class="chapter" data-level="9.2.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#gaussian-distribution-normal-distribution"><i class="fa fa-check"></i><b>9.2.1</b> Gaussian Distribution (‘Normal Distribution’)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#a-likelihood-function-for-the-vaccine-data"><i class="fa fa-check"></i><b>9.3</b> A likelihood function for the vaccine data</a></li>
<li class="chapter" data-level="9.4" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#bayesian-inference-i"><i class="fa fa-check"></i><b>9.4</b> Bayesian Inference I</a></li>
<li class="chapter" data-level="9.5" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#returning-to-example-1"><i class="fa fa-check"></i><b>9.5</b> Returning to Example 1</a><ul>
<li class="chapter" data-level="9.5.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#likelihood"><i class="fa fa-check"></i><b>9.5.1</b> Likelihood</a></li>
<li class="chapter" data-level="9.5.2" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#prior"><i class="fa fa-check"></i><b>9.5.2</b> Prior</a></li>
<li class="chapter" data-level="9.5.3" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#marginal-probability-of-the-data"><i class="fa fa-check"></i><b>9.5.3</b> Marginal probability of the data</a></li>
<li class="chapter" data-level="9.5.4" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#posterior-probability"><i class="fa fa-check"></i><b>9.5.4</b> Posterior probability</a></li>
<li class="chapter" data-level="9.5.5" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#and-now-again-for"><i class="fa fa-check"></i><b>9.5.5</b> And now again, for</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#bayesian-inference-ii"><i class="fa fa-check"></i><b>9.6</b> Bayesian Inference II</a></li>
<li class="chapter" data-level="9.7" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#back-to-our-incidence-rates"><i class="fa fa-check"></i><b>9.7</b> Back to our incidence rates</a><ul>
<li class="chapter" data-level="9.7.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#brazil"><i class="fa fa-check"></i><b>9.7.1</b> Brazil</a></li>
<li class="chapter" data-level="9.7.2" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#turkey"><i class="fa fa-check"></i><b>9.7.2</b> Turkey</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="case-studies.html"><a href="case-studies.html"><i class="fa fa-check"></i><b>10</b> Case Studies</a><ul>
<li class="chapter" data-level="10.1" data-path="case-studies.html"><a href="case-studies.html#vot-data"><i class="fa fa-check"></i><b>10.1</b> VOT Data</a><ul>
<li class="chapter" data-level="10.1.1" data-path="case-studies.html"><a href="case-studies.html#loading-the-data"><i class="fa fa-check"></i><b>10.1.1</b> Loading the Data</a></li>
<li class="chapter" data-level="10.1.2" data-path="case-studies.html"><a href="case-studies.html#explorotary-data-analysis-and-descriptive-statistics"><i class="fa fa-check"></i><b>10.1.2</b> Explorotary Data Analysis and Descriptive Statistics</a></li>
<li class="chapter" data-level="10.1.3" data-path="case-studies.html"><a href="case-studies.html#how-long-is-the-difference-between-voiced-and-unvoiced-stops-in-english-and-in-korean"><i class="fa fa-check"></i><b>10.1.3</b> How long is the difference between voiced and unvoiced stops in English and in Korean?</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="case-studies.html"><a href="case-studies.html#priming-experiment"><i class="fa fa-check"></i><b>10.2</b> Priming Experiment</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="your-term-paper.html"><a href="your-term-paper.html"><i class="fa fa-check"></i><b>11</b> Your term paper</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="errorless_lms" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Error-less Linear Models</h1>
<ul>
<li><p>What I am going to call <em>‘error-less linear models’</em> are actually <em>systems of linear equations</em> like those you might recall from school (of the <em>‘2=a+3x; 1=a+x; solve for a and x’</em>-variety). I’ll call them <em>error-less linear models</em>, because in many important ways they resemble the class of statistical models we will use in this course: (Generalized) Linear Models.</p></li>
<li><p>In this section we are going to explore <strong>error-less</strong> linear models, i.e. linear models that work on <strong>idealized</strong> data, when there is no measurement error, and when the <em>‘correct’</em> model describing the data is known.</p></li>
<li><p>The basic form of a linear regression model, in a form that works for <em>idealized</em> data (i.e., data perfectly follow some hypothesized function):
<!-- 
- What is regression?
- What is linear about this model?
--></p></li>
</ul>
<p><span class="math display">\[ \underbrace{Y}_{\text{dependent variable}} =
            \overbrace{\underbrace{a}_{\text{intercept}}}^{\text{additive term}} + 
            \overbrace{\underbrace{b_1}_{\text{slope}} * \underbrace{X_{1}}_{\text{predictor}}}^{\text{additive term}} + 
            \overbrace{\underbrace{b_2}_{\text{slope}} * \underbrace{X_{2} }_{\text{predictor}}}^{\text{additive term}} +  
            \ldots\]</span>
<!--  \overbrace{\ldots}^{\text{more additive terms}} --></p>
<ul>
<li>The typical dataset we will be working with has a structure similar to the one below:</li>
</ul>
<table>
<colgroup>
<col width="21%" />
<col width="21%" />
<col width="26%" />
<col width="30%" />
</colgroup>
<thead>
<tr class="header">
<th>dependent variable<br>(<span class="math inline">\(Y\)</span>)</th>
<th align="left">predictor 1<br>(<span class="math inline">\(X_1\)</span>)</th>
<th align="left">predictor 2<br>(<span class="math inline">\(X_2\)</span>)</th>
<th align="left">(further predictors)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2.95</td>
<td align="left">1.1</td>
<td align="left">2.2</td>
<td align="left">(…)</td>
</tr>
<tr class="even">
<td>9.1</td>
<td align="left">2.9</td>
<td align="left">-4.0</td>
<td align="left">(…)</td>
</tr>
<tr class="odd">
<td>5</td>
<td align="left">3.1</td>
<td align="left">-1.4</td>
<td align="left">(…)</td>
</tr>
<tr class="even">
<td>…</td>
<td align="left">…</td>
<td align="left">…</td>
<td align="left">(…)</td>
</tr>
</tbody>
</table>
<ul>
<li>What the variables represent will depend on the problem you’re studying and the question you’re asking
<ul>
<li>dependent variable (e.g., hours of sleep/day)</li>
<li>predictor 1 (e.g., daily food intake in kg)</li>
<li>predictor 2 (e.g., deviation from average weight)</li>
</ul></li>
</ul>
<!--
 
-->
<!--  \overbrace{\ldots}^{\text{more additive terms}} -->
<ul>
<li>The <strong>dependent variable</strong> <span class="math inline">\(y\)</span> is assumed to depend on the predictors <span class="math inline">\(x_1, x_2, \ldots\)</span>.</li>
<li>The <strong>predictors</strong> <span class="math inline">\(x_1, x_2, \ldots\)</span> can be <strong>independent variables</strong> (i.e., under experimental control), or other types of covariates (i.e., simply observed).</li>
<li><p>The model is called <em>linear</em> because <span class="math inline">\(y\)</span> is assumed to be a linear function of the <span class="math inline">\(x_1, x_2, \ldots\)</span>. That <span class="math inline">\(y\)</span> increases by some fixed amount <span class="math inline">\(\Delta y\)</span> for every increase of <span class="math inline">\(\Delta x_i\)</span> in <span class="math inline">\(x_i\)</span>.</p></li>
<li><p>Two types are usually distinguished: <em>single-variable</em>, and <em>multi-variable</em> (also: <em>simple linear regression</em>, <em>multiple linear regression</em>).
<!-- 'univariate', and 'multivariate' stand for the number of dependent variables, *not* the number of predictors  --></p></li>
<li><p>The above equation is about vectors of observations. Let’s see how it translates to statements about specific observations. Please note that <span class="math inline">\(Y\)</span>, <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span> in the equation above are all vectors, while <span class="math inline">\(y_i\)</span>, <span class="math inline">\(x_{1,i}\)</span>, <span class="math inline">\(x_{2,i}\)</span> are all specific numbers (from the <span class="math inline">\(i\)</span>-th row).</p></li>
</ul>
<p><span class="math display">\[ \underbrace{y_i}_{\text{dependent variable}} =
            \overbrace{\underbrace{a}_{\text{intercept}}}^{\text{additive term}} + 
            \overbrace{\underbrace{b_1}_{\text{slope}} * \underbrace{x_{1,i}}_{\text{predictor}}}^{\text{additive term}} +
            \overbrace{\underbrace{b_2}_{\text{slope}} * \underbrace{x_{2,i} }_{\text{predictor}}}^{\text{additive term}} +  
            \ldots\]</span></p>
<ul>
<li><p>For two predictors <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, and three observerations like in the table above, this equation translates to the following equation system
<span class="math display">\[ y_1 = a + b_1\cdot x_{1,1} + b_2\cdot x_{2,1} \\
y_2 = a + b_1\cdot x_{1,2} + b_2\cdot x_{2,3} \\
y_3 = a + b_1\cdot x_{1,3} + b_2\cdot x_{2,3}\]</span></p></li>
<li><p>That is,
<span class="math display">\[ 2.95 = a + b_1\cdot 1.1 + b_2\cdot 2.2 \\
9.1 = a + b_1\cdot 2.9 + b_2\cdot (-4) \\
5 = a + b_1\cdot 3.1 + b_2\cdot (-1.4)\]</span></p></li>
<li><p>In this case, there is a perfect solution: <span class="math inline">\(a \approx 7.90\)</span>, <span class="math inline">\(b_1 \approx -1.60\)</span>, <span class="math inline">\(b_2 \approx -1.45\)</span> (rounded to two decimal places).
<span class="math display">\[ \underbrace{y}_{\text{dependent variable}} =
          \overbrace{\underbrace{7.9}_{\text{intercept}}}^{\text{additive term}} +
          \overbrace{\underbrace{(-1.60)}_{\text{slope}} * \underbrace{x_1}_{\text{predictor}}}^{\text{additive term}} + 
          \overbrace{\underbrace{(-1.45)}_{\text{slope}} * \underbrace{x_2}_{\text{predictor}}}^{\text{additive term}} +  
          \ldots\]</span></p></li>
</ul>
<table>
<colgroup>
<col width="40%" />
<col width="15%" />
<col width="12%" />
<col width="15%" />
<col width="17%" />
</colgroup>
<thead>
<tr class="header">
<th>model prediction</th>
<th align="left">dependent variable</th>
<th align="left">predictor 1</th>
<th align="left">predictor 2</th>
<th align="left">(further predictors)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(7.9-1.6\cdot 1.1-1.45\cdot 2.2\)</span></td>
<td align="left">2.95</td>
<td align="left">1.1</td>
<td align="left">2.2</td>
<td align="left">(…)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(7.9-1.6\cdot 2.9-1.45\cdot (-4)\)</span></td>
<td align="left">9.1</td>
<td align="left">2.9</td>
<td align="left">-4.0</td>
<td align="left">(…)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(7.9-1.6\cdot 3.1-1.45\cdot (-1.4)\)</span></td>
<td align="left">5</td>
<td align="left">3.1</td>
<td align="left">-1.4</td>
<td align="left">(…)</td>
</tr>
<tr class="even">
<td></td>
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
<td align="left">(…)</td>
</tr>
</tbody>
</table>
<ul>
<li>Throughout this course, we will make use of the (Generalized) Linear Model as the main statistical model because it is:
<ul>
<li>fairly easy to use (implemented in most programming languages)</li>
<li>sufficiently versatile for most practical purposes (can handle most problems you would want to solve at this point)</li>
<li>well-studied (all mistakes you will make have already been made, and written about)</li>
</ul></li>
</ul>
<div id="single-variable-models" class="section level2">
<h2><span class="header-section-number">4.1</span> Single-variable models</h2>
<ul>
<li>Let’s take a look at a dataset of taxi rides in a country far far away. Imagine that I don’t speak the local language, but I need to go places, and in the process, I would like to understand how the cab fare system works.</li>
<li>I have taken 18 taxi rides, and recorded the travel distance, as well as the taxi fare for reach ride.</li>
<li>The following plot shows each of these measurements as a point with the distances (in km) on the x-axis, and the fare (money units, MU) on the y-axis.</li>
<li>This dataset is interesting, because you probably understand the typical relationships between ride distance and fare fairly well – it is linear. So it is an ideal example for illustrating linear models.</li>
</ul>
<p><img src="LectureNotes_files/figure-html/carsPerfect1-1.png" width="672" /></p>
<ul>
<li>Unsurprisingly, we can see clearly that the fare increases with distance. In other words, <em>distance</em> and <em>fare</em> have a positive relationship (if one increases, so does the other).</li>
<li><p>The relationship between the two variables is so strong that if we know the value of one of the two variables for a particular data point, we can predict the value of the other with a high degree of confidence. (You might want to say that I can predict if with <em>absolute certainty</em>, but that presupposes precise knowledge of the cab fare system in that city, <em>and</em> an extreme degree of trust towards the local taxi drivers. Let’s assume that we don’t have either.)</p></li>
<li><p>We can make that prediction with such a high degree of certainty because all the points seem to lie on a line. If we learned the function that describes this line, we could learn much more from this dataset than the simple fact that the two variables a positive related.</p></li>
<li><p>That is unsurprising to begin with, but we may want to know <strong>how exactly</strong> they are related. A simple way to capture this relationship is to try and describe it with this function:</p></li>
</ul>
<p><span class="math display">\[ \text{fare} = a + b \cdot \text{distance} \]</span></p>
<ul>
<li>What this equation says is that if we take a value for distance, multiply it by <em>some number</em> called <span class="math inline">\(b\)</span>, and then add <em>another number</em> called <span class="math inline">\(a\)</span>, we will know the fare that corresponds to this distance. (In other words, this equation posits that the relationship between <em>distance</em> and <em>fare</em> is linear.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>)</li>
<li>In this particular case the relationship is <span class="math inline">\(\text{fare} = 4 + 2.5 \cdot \text{distance}\)</span>, which means that <span class="math inline">\(a=4\)</span>, and <span class="math inline">\(b=2.5\)</span>. We can verify that this equation is indeed the correct generalization by visualizing this function as a line in the plot below: As you can see, it accurately describes all the points in the graph.</li>
</ul>
<p><img src="LectureNotes_files/figure-html/carsPerfect2-1.png" width="672" /></p>
<ul>
<li>Importantly, if we conceptualize <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> as just some numbers that we need to add and multiply by, we will miss an important insight: Both numbers have useful interpretations. In this case, <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> can be interpreted as follows:
<ul>
<li><span class="math inline">\(a\)</span> is called the <strong>intercept</strong>: It can be interpreted as the value of <em>fare</em> when <em>distance</em> is 0. In this case, the intercept is <span class="math inline">\(4~MU\)</span>, which is the amount you have to pay if you get in and change your mind after the taxometer has been switched on (if the taxi driver is a real stickler for rules).</li>
<li><span class="math inline">\(b\)</span> is called the <strong>slope</strong> for distance: It can be interpreted as the additional amount of money you have to pay for every additional kilometer traveled. A slope of <span class="math inline">\(2.5\)</span> means that a distance increase of <span class="math inline">\(1~km\)</span> increases the fare by <span class="math inline">\(2.5~MU\)</span>.</li>
</ul></li>
<li>The plot below illustrates these interpretations:</li>
</ul>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<!-- TODO: Take-away message. -->
</div>
<div id="multi-variable-models" class="section level2">
<h2><span class="header-section-number">4.2</span> Multi-variable models</h2>
<ul>
<li><p>Let’s imagine that this imaginary city also has many bridges. Since I wasn’t sure whether bridge tolls apply, I also recorded the number of bridges crossed on each trip. In the previous section, we’ve looked at the subset of data where no bridges were crossed. Let’s see how the fare depends not only on distance travelled, but also on the number of bridges crossed.</p></li>
<li><p>Now, we are looking at the relationship between three variables, and the data frame looks as follows:</p></li>
</ul>
<div id="htmlwidget-e98ac0809a4d0adef7d4" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-e98ac0809a4d0adef7d4">{"x":{"filter":"none","vertical":false,"data":[[64,54,61.5,69,26.5,66.5,61.5,19,56.5,51.5,21.5,26.5,74,56.5,101.5,86.5,89,94,81.5,36.5,71.5,31.5,84,21.5,59,49,71.5,96.5,41.5,44,71.5,56.5,89,21.5,41.5,46.5,24,54,51.5,69,41.5,64,39,69,51.5,74,74,36.5,26.5,36.5,66.5,49,24,49,51.5,76.5,76.5,79,61.5,66.5,44,74,91.5,81.5,79,44,89,66.5,61.5,31.5,99,51.5,86.5,46.5,76.5,71.5,56.5,84,71.5,59,61.5,69,94,54,59,41.5,19,36.5,74,81.5,61.5,34,54,49,59,36.5,39,29,64,46.5,54,59,61.5,79,91.5,46.5,84,66.5,84,26.5,69,16.5,86.5,66.5,56.5,46.5,59,69,54,54,29,61.5,71.5,51.5,39,84,41.5,49,56.5,99,79,104,24,34,46.5,69,16.5,64,39,56.5,96.5,64,34,34,59,29,66.5,49,71.5,29,51.5,51.5,11.5,34,69,94,31.5,39,76.5,44,59,46.5,79,86.5,59,56.5,49,81.5,36.5,74,31.5,89,61.5,46.5,56.5,64,44,14,39,74,44,54,49,31.5,41.5,44,41.5,79,66.5,81.5,91.5,64,76.5,64,51.5,54,64,76.5],[12,14,5,20,5,13,9,4,9,11,5,3,20,5,19,17,16,20,19,13,7,7,18,3,8,14,11,17,5,12,15,3,18,7,15,7,6,6,19,12,7,14,14,6,7,10,14,11,7,7,11,4,4,8,15,13,15,12,15,9,14,12,17,11,16,16,20,15,17,11,18,17,19,9,9,13,15,20,19,16,19,8,18,10,4,3,6,9,16,15,11,4,12,12,14,3,10,10,20,13,8,10,13,18,19,17,16,7,12,9,16,5,15,19,11,5,6,10,16,18,6,3,9,5,12,14,13,6,17,20,14,20,8,12,15,14,3,4,4,19,19,16,8,6,12,4,17,18,17,8,13,3,3,10,18,16,9,6,19,10,20,11,10,13,18,7,16,17,5,8,3,14,7,3,13,8,6,4,8,18,4,4,10,5,11,8,9,20,5,13,15,10,11,18,9,20,6,17],[6,3,9,3,2,6,7,1,6,4,1,3,4,8,10,8,9,8,6,0,10,2,7,2,7,2,8,10,5,2,6,9,8,0,0,5,1,7,-0,7,4,5,-0,10,6,9,7,1,1,3,7,7,2,5,2,8,7,9,4,8,1,8,9,10,7,0,7,5,3,-0,10,1,7,4,10,7,3,6,4,3,2,9,9,5,9,6,-0,2,6,8,6,4,4,3,4,5,2,0,2,2,6,6,5,6,8,-0,8,9,10,0,5,-0,9,3,5,6,8,8,2,1,2,10,9,7,1,9,1,6,2,9,8,10,0,-0,1,6,1,10,5,1,9,4,2,3,5,3,4,0,5,1,3,8,-0,1,4,10,1,4,5,3,1,3,10,10,2,7,1,7,4,10,4,10,8,7,4,8,5,0,3,5,6,8,4,3,2,4,3,5,10,9,10,7,9,3,5,-0,9,6]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>fare_mu<\/th>\n      <th>distance_km<\/th>\n      <th>n_bridges<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"columnDefs":[{"className":"dt-right","targets":[0,1,2]}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<ul>
<li>Let’s see if there even is a relationship. Let’s look at the effect of bridges at distance=<span class="math inline">\(3\,km\)</span>.</li>
</ul>
<p><img src="LectureNotes_files/figure-html/carsPerfect2A-1.png" width="672" /></p>
<ul>
<li><p>Yup, it looks like there is a positive effect. Let’s model it in additive fashion:</p></li>
<li>We will again assume that the relationships between fare and distance, as well as between fare and number of bridges crossed is linear, and that they contribute to the fare independently. We can now describe the relationship with the following equation:
<span class="math display">\[ fare = a + b_1 \cdot distance + b_2  \cdot N_{bridges} \]</span></li>
<li>The correct parameter values for this equation are <span class="math inline">\(a=4\)</span>, <span class="math inline">\(b_1 = 2.5\)</span> (as previously), and <span class="math inline">\(b_2=5\)</span>. The interpretation of the coefficients is similar to the previous section:
<ul>
<li><span class="math inline">\(a\)</span> (the <strong>intercept</strong>) is the fare when no bridges have been crossed, and the travel distance is zero.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></li>
<li><span class="math inline">\(b_1\)</span> (the <strong>slope</strong> for <strong>distance</strong>) is the additional fare for every additional kilometer.</li>
<li><span class="math inline">\(b_2\)</span> (the <strong>slope</strong> for <strong><span class="math inline">\(N_{bridges}\)</span></strong>) is the additional fare for every additional bridge.</li>
</ul></li>
</ul>
<!-- Consider 
- integrating how the intercept wouldn't make any sense with number of passengers. 
- use day/night for an interaction. 
-->
<ul>
<li><p>The following plot shows the data vis-à-vis the linear model fits. You can turn the plot in the browser. Drag it around using your mouse.</p></li>
<li><p>Because we are dealing with a relationship between three variables, every datapoint is a point in three-dimensional space (x-axis: distance, y-axis: number of bridges, z-axis: fare). The multi-variable model fit is illustrated by the <em>blue plane</em> perfectly fitting through all points, which rises with increasing distance and/or number of bridges crossed.</p></li>
<li><p>The green plane below shows the single-variable model from the last section (<span class="math inline">\(fare = 4 + 2.5\cdot distance\)</span>) for comparison. The plane corresponding to the single-variable model does not rise with the number of bridges crossed. This is because it is not used as a predictor in that model.</p></li>
<li><p>You will also notice that the red plane and the black plane intersect in a line at <span class="math inline">\(N_{bridges} = 0\)</span>. This is because the two model equations <span class="math inline">\(a + b_1 * distance\)</span> and <span class="math inline">\(a + b_1 * distance + b_2 * N_{bridges}\)</span> are equivalent for <span class="math inline">\(N_{bridges} = 0\)</span>.</p></li>
</ul>
<div id="rgl88002" style="width:720px;height:480px;" class="rglWebGL html-widget"></div>
<script type="application/json" data-for="rgl88002">{"x":{"material":{"color":"#000000","alpha":1,"lit":true,"ambient":"#000000","specular":"#FFFFFF","emission":"#000000","shininess":50,"smooth":true,"front":"filled","back":"filled","size":3,"lwd":1,"fog":true,"point_antialias":false,"line_antialias":false,"texture":null,"textype":"rgb","texmipmap":false,"texminfilter":"linear","texmagfilter":"linear","texenvmap":false,"depth_mask":true,"depth_test":"less","isTransparent":false,"polygon_offset":[0,0],"margin":"","floating":false},"rootSubscene":7,"objects":{"13":{"id":13,"type":"spheres","material":{},"vertices":[[12,6,64],[14,3,54],[5,9,61.5],[20,3,69],[5,2,26.5],[13,6,66.5],[9,7,61.5],[4,1,19],[9,6,56.5],[11,4,51.5],[5,1,21.5],[3,3,26.5],[20,4,74],[5,8,56.5],[19,10,101.5],[17,8,86.5],[16,9,89],[20,8,94],[19,6,81.5],[13,0,36.5],[7,10,71.5],[7,2,31.5],[18,7,84],[3,2,21.5],[8,7,59],[14,2,49],[11,8,71.5],[17,10,96.5],[5,5,41.5],[12,2,44],[15,6,71.5],[3,9,56.5],[18,8,89],[7,0,21.5],[15,0,41.5],[7,5,46.5],[6,1,24],[6,7,54],[19,-0,51.5],[12,7,69],[7,4,41.5],[14,5,64],[14,-0,39],[6,10,69],[7,6,51.5],[10,9,74],[14,7,74],[11,1,36.5],[7,1,26.5],[7,3,36.5],[11,7,66.5],[4,7,49],[4,2,24],[8,5,49],[15,2,51.5],[13,8,76.5],[15,7,76.5],[12,9,79],[15,4,61.5],[9,8,66.5],[14,1,44],[12,8,74],[17,9,91.5],[11,10,81.5],[16,7,79],[16,0,44],[20,7,89],[15,5,66.5],[17,3,61.5],[11,-0,31.5],[18,10,99],[17,1,51.5],[19,7,86.5],[9,4,46.5],[9,10,76.5],[13,7,71.5],[15,3,56.5],[20,6,84],[19,4,71.5],[16,3,59],[19,2,61.5],[8,9,69],[18,9,94],[10,5,54],[4,9,59],[3,6,41.5],[6,-0,19],[9,2,36.5],[16,6,74],[15,8,81.5],[11,6,61.5],[4,4,34],[12,4,54],[12,3,49],[14,4,59],[3,5,36.5],[10,2,39],[10,0,29],[20,2,64],[13,2,46.5],[8,6,54],[10,6,59],[13,5,61.5],[18,6,79],[19,8,91.5],[17,-0,46.5],[16,8,84],[7,9,66.5],[12,10,84],[9,0,26.5],[16,5,69],[5,-0,16.5],[15,9,86.5],[19,3,66.5],[11,5,56.5],[5,6,46.5],[6,8,59],[10,8,69],[16,2,54],[18,1,54],[6,2,29],[3,10,61.5],[9,9,71.5],[5,7,51.5],[12,1,39],[14,9,84],[13,1,41.5],[6,6,49],[17,2,56.5],[20,9,99],[14,8,79],[20,10,104],[8,0,24],[12,-0,34],[15,1,46.5],[14,6,69],[3,1,16.5],[4,10,64],[4,5,39],[19,1,56.5],[19,9,96.5],[16,4,64],[8,2,34],[6,3,34],[12,5,59],[4,3,29],[17,4,66.5],[18,0,49],[17,5,71.5],[8,1,29],[13,3,51.5],[3,8,51.5],[3,-0,11.5],[10,1,34],[18,4,69],[16,10,94],[9,1,31.5],[6,4,39],[19,5,76.5],[10,3,44],[20,1,59],[11,3,46.5],[10,10,79],[13,10,86.5],[18,2,59],[7,7,56.5],[16,1,49],[17,7,81.5],[5,4,36.5],[8,10,74],[3,4,31.5],[14,10,89],[7,8,61.5],[3,7,46.5],[13,4,56.5],[8,8,64],[6,5,44],[4,0,14],[8,3,39],[18,5,74],[4,6,44],[4,8,54],[10,4,49],[5,3,31.5],[11,2,41.5],[8,4,44],[9,3,41.5],[20,5,79],[5,10,66.5],[13,9,81.5],[15,10,91.5],[10,7,64],[11,9,76.5],[18,3,64],[9,5,51.5],[20,-0,54],[6,9,64],[17,6,76.5]],"colors":[[1,0,0,1]],"radii":[[0.75]],"centers":[[12,6,64],[14,3,54],[5,9,61.5],[20,3,69],[5,2,26.5],[13,6,66.5],[9,7,61.5],[4,1,19],[9,6,56.5],[11,4,51.5],[5,1,21.5],[3,3,26.5],[20,4,74],[5,8,56.5],[19,10,101.5],[17,8,86.5],[16,9,89],[20,8,94],[19,6,81.5],[13,0,36.5],[7,10,71.5],[7,2,31.5],[18,7,84],[3,2,21.5],[8,7,59],[14,2,49],[11,8,71.5],[17,10,96.5],[5,5,41.5],[12,2,44],[15,6,71.5],[3,9,56.5],[18,8,89],[7,0,21.5],[15,0,41.5],[7,5,46.5],[6,1,24],[6,7,54],[19,-0,51.5],[12,7,69],[7,4,41.5],[14,5,64],[14,-0,39],[6,10,69],[7,6,51.5],[10,9,74],[14,7,74],[11,1,36.5],[7,1,26.5],[7,3,36.5],[11,7,66.5],[4,7,49],[4,2,24],[8,5,49],[15,2,51.5],[13,8,76.5],[15,7,76.5],[12,9,79],[15,4,61.5],[9,8,66.5],[14,1,44],[12,8,74],[17,9,91.5],[11,10,81.5],[16,7,79],[16,0,44],[20,7,89],[15,5,66.5],[17,3,61.5],[11,-0,31.5],[18,10,99],[17,1,51.5],[19,7,86.5],[9,4,46.5],[9,10,76.5],[13,7,71.5],[15,3,56.5],[20,6,84],[19,4,71.5],[16,3,59],[19,2,61.5],[8,9,69],[18,9,94],[10,5,54],[4,9,59],[3,6,41.5],[6,-0,19],[9,2,36.5],[16,6,74],[15,8,81.5],[11,6,61.5],[4,4,34],[12,4,54],[12,3,49],[14,4,59],[3,5,36.5],[10,2,39],[10,0,29],[20,2,64],[13,2,46.5],[8,6,54],[10,6,59],[13,5,61.5],[18,6,79],[19,8,91.5],[17,-0,46.5],[16,8,84],[7,9,66.5],[12,10,84],[9,0,26.5],[16,5,69],[5,-0,16.5],[15,9,86.5],[19,3,66.5],[11,5,56.5],[5,6,46.5],[6,8,59],[10,8,69],[16,2,54],[18,1,54],[6,2,29],[3,10,61.5],[9,9,71.5],[5,7,51.5],[12,1,39],[14,9,84],[13,1,41.5],[6,6,49],[17,2,56.5],[20,9,99],[14,8,79],[20,10,104],[8,0,24],[12,-0,34],[15,1,46.5],[14,6,69],[3,1,16.5],[4,10,64],[4,5,39],[19,1,56.5],[19,9,96.5],[16,4,64],[8,2,34],[6,3,34],[12,5,59],[4,3,29],[17,4,66.5],[18,0,49],[17,5,71.5],[8,1,29],[13,3,51.5],[3,8,51.5],[3,-0,11.5],[10,1,34],[18,4,69],[16,10,94],[9,1,31.5],[6,4,39],[19,5,76.5],[10,3,44],[20,1,59],[11,3,46.5],[10,10,79],[13,10,86.5],[18,2,59],[7,7,56.5],[16,1,49],[17,7,81.5],[5,4,36.5],[8,10,74],[3,4,31.5],[14,10,89],[7,8,61.5],[3,7,46.5],[13,4,56.5],[8,8,64],[6,5,44],[4,0,14],[8,3,39],[18,5,74],[4,6,44],[4,8,54],[10,4,49],[5,3,31.5],[11,2,41.5],[8,4,44],[9,3,41.5],[20,5,79],[5,10,66.5],[13,9,81.5],[15,10,91.5],[10,7,64],[11,9,76.5],[18,3,64],[9,5,51.5],[20,-0,54],[6,9,64],[17,6,76.5]],"ignoreExtent":false,"fastTransparency":true,"flags":32771},"15":{"id":15,"type":"text","material":{"lit":false,"margin":0,"floating":true,"edge":[0,1,1]},"vertices":[["NaN",4,1]],"colors":[[0,0,0,1]],"texts":[["Distance (km)"]],"cex":[[1]],"adj":[[0.5,0.5]],"centers":[["NaN",4,1]],"family":[["sans"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"16":{"id":16,"type":"text","material":{"lit":false,"margin":1,"floating":true,"edge":[1,1,1]},"vertices":[["NaN",4,1]],"colors":[[0,0,0,1]],"texts":[["N bridges"]],"cex":[[1]],"adj":[[0.5,0.5]],"centers":[["NaN",4,1]],"family":[["sans"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"17":{"id":17,"type":"text","material":{"lit":false,"margin":2,"floating":true,"edge":[1,1,1]},"vertices":[["NaN",4,1]],"colors":[[0,0,0,1]],"texts":[["Fare (MU)"]],"cex":[[1]],"adj":[[0.5,0.5]],"centers":[["NaN",4,1]],"family":[["sans"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"18":{"id":18,"type":"planes","material":{"alpha":0.498039215803146,"isTransparent":true},"vertices":[[2.76650667190552,10.1373491287231,61.6030120849609],[2.7665069103241,-0.1373490691185,10.2295217514038],[2.76650667190552,-0.137348979711533,10.2295217514038]],"colors":[[0,0,1,0.498039215803146]],"offsets":[[4]],"centers":[[2.7665069103241,3.28755044937134,27.3540191650391],[8.58883571624756,3.28755044937134,41.9098434448242],[14.4111652374268,6.71244955062866,73.5901641845703],[14.4111633300781,10.1373491287231,90.7146606445312]],"normals":[[2.5,5,-1]],"ignoreExtent":true,"flags":32803},"19":{"id":19,"type":"planes","material":{},"vertices":[[2.76650667190552,-0.1373490691185,10.9162664413452],[2.76650667190552,10.1373491287231,10.9162664413452],[20.2334938049316,10.1373491287231,54.5837326049805]],"colors":[[0,1,0,1]],"offsets":[[4]],"centers":[[8.58883571624756,6.71244955062866,25.4720897674561],[14.4111652374268,3.28755044937134,40.0279121398926],["NaN","NaN","NaN"],["NaN","NaN","NaN"]],"normals":[[2.5,0,-1]],"ignoreExtent":true,"flags":32771},"11":{"id":11,"type":"light","vertices":[[0,0,1]],"colors":[[1,1,1,1],[1,1,1,1],[1,1,1,1]],"viewpoint":true,"finite":false},"10":{"id":10,"type":"background","material":{},"colors":[[0.298039227724075,0.298039227724075,0.298039227724075,1]],"centers":[[0,0,0]],"sphere":false,"fogtype":"none","fogscale":1,"flags":32768},"12":{"id":12,"type":"background","material":{"lit":false,"back":"lines"},"colors":[[1,1,1,1]],"centers":[[0,0,0]],"sphere":false,"fogtype":"none","fogscale":1,"flags":32768},"14":{"id":14,"type":"bboxdeco","material":{"front":"lines","back":"lines"},"vertices":[[5,"NA","NA"],[10,"NA","NA"],[15,"NA","NA"],[20,"NA","NA"],["NA",0,"NA"],["NA",2,"NA"],["NA",4,"NA"],["NA",6,"NA"],["NA",8,"NA"],["NA",10,"NA"],["NA","NA",20],["NA","NA",40],["NA","NA",60],["NA","NA",80],["NA","NA",100]],"colors":[[0,0,0,1]],"axes":{"mode":["pretty","pretty","pretty"],"step":[5,2,20],"nticks":[5,5,5],"marklen":[15,15,15],"expand":[1.02999997138977,1.02999997138977,1.02999997138977]},"draw_front":true},"7":{"id":7,"type":"subscene","par3d":{"antialias":8,"FOV":30,"ignoreExtent":false,"listeners":7,"mouseMode":{"none":"none","left":"trackball","right":"zoom","middle":"fov","wheel":"pull"},"observer":[0,0,237.794296264648],"modelMatrix":[[3.21208238601685,0,0,-36.9389457702637],[0,1.86761462688446,0.554727494716644,-41.3735847473145],[0,-5.13122892379761,0.201904311776161,-223.798126220703],[0,0,0,1]],"projMatrix":[[3.73205065727234,0,0,0],[0,3.73205065727234,0,0],[0,0,-3.86370348930359,-857.220947265625],[0,0,-1,0]],"skipRedraw":false,"userMatrix":[[1,0,0,0],[0,0.342020143325668,0.939692620785909,0],[0,-0.939692620785909,0.342020143325668,0],[0,0,0,1]],"userProjection":[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],"scale":[3.21208238601685,5.46053981781006,0.590328693389893],"viewport":{"x":0,"y":0,"width":1,"height":1},"zoom":1,"bbox":[2.76650667190552,20.2334938049316,-0.1373490691185,10.1373491287231,10.2295217514038,105.270477294922],"windowRect":[160,232,416,488],"family":"sans","font":1,"cex":1,"useFreeType":true,"fontname":"/home/pavel3/R/x86_64-pc-linux-gnu-library/4.1/rgl/fonts/FreeSans.ttf","maxClipPlanes":8,"glVersion":4.6,"activeSubscene":0},"embeddings":{"viewport":"replace","projection":"replace","model":"replace","mouse":"replace"},"objects":[12,14,13,15,16,17,18,19,11],"subscenes":[],"flags":34099}},"crosstalk":{"key":[],"group":[],"id":[],"options":[]},"width":720,"height":480,"context":{"shiny":false,"rmarkdown":null},"players":[],"webGLoptions":{"preserveDrawingBuffer":true}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="models-with-categorical-predictors" class="section level2">
<h2><span class="header-section-number">4.3</span> Models with categorical predictors</h2>
<ul>
<li>Predictors on the <strong>nominal</strong> or <strong>ordinal scale</strong> (as opposed to <strong>ratio</strong>, or <strong>interval scale</strong>) are not naturally represented by numbers. For example:
<ul>
<li>Speaker gender</li>
<li>Presence or absence of wh-movement</li>
<li>word order (e.g., SOV, SVO, VSO)</li>
<li>size (long, short)</li>
</ul></li>
<li><p>We can represent them numerically, but there are many coding options. We can represent a factor with two levels by (i) 0 and 1, or (ii) by -1 and 1, or (iii) by +0.5 and -0.5, or even (iv) 23 and 42.</p></li>
<li><p>In the case of the taxi fares, one such predictor is the color of the taxi: I’ve observed red and yellow taxis, and I didn’t know if there is possibly a difference in their pricing. In order to determine whether there is, I decided to take a ride in both types. (All the data in the previous sections was for yellow cabs only.)</p></li>
<li><p>The following plot shows the relationship between fare and cab color (for <span class="math inline">\(distance=10~km\)</span>, and <span class="math inline">\(N_{bridges} = 0\)</span>). The x-axis shows the <strong>contrast</strong> for cab color (<em>the numerical representation of of the categorical variable ‘color’</em>). The y-axis shows the cab fare.</p></li>
</ul>
<!-- (\#eq:justcolor) -->
<!-- \@ref(eq:justcolor) -->
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-77-1.png" width="480" style="display: block; margin: auto;" /></p>
<ul>
<li>While the choice of the coding scheme is somewhat arbitrary, it will affect the interpretation of the <strong>coefficients</strong> (that is, the parameters of the linear model, i.e., the intercept and the slope).
<!-- Make sure whe word 'coefficients' is known at this point, ideally by moving the deterministic form of the LM forward. -->
In other words, <strong>model parameterization</strong> (or: <strong>contrast specification</strong>) affects the meaning of the coefficients. We will use equation <a href="errorless_lms.html#eq:justcolor">(4.1)</a> to describe the relationship, where <em>cCabColorRed</em> is a numerical representation of the cab color.</li>
</ul>
<p><span class="math display" id="eq:justcolor">\[\begin{equation} 
\text{fare} = a + b \cdot \text{cCabColorRed} 
\tag{4.1}
\end{equation}\]</span></p>
<ul>
<li>We will consider two ways representing color: <strong>treatment contrasts</strong>, <strong>sum contrasts</strong>. For the interpretations of the coefficients, keep in mind that we are using a subset of the data with <span class="math inline">\(10\,km\)</span> rides, when no bridges have been crossed.</li>
</ul>
<table>
<colgroup>
<col width="19%" />
<col width="42%" />
<col width="38%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th align="left"><strong>treatment contrasts</strong></th>
<th align="left"><strong>sum contrasts</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>contrast coding</td>
<td align="left">yellow = 0; red = 1</td>
<td align="left">yellow = -0.5; red = 0.5</td>
</tr>
<tr class="even">
<td><em><span class="math inline">\(a\)</span> (intercept) interpretation</em></td>
<td align="left">The fare ride in a yellow taxi</td>
<td align="left">The average of the fares for a ride in a yellow taxi and one in a red taxi.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></td>
</tr>
<tr class="odd">
<td><em><span class="math inline">\(b\)</span> (slope) interpretation</em></td>
<td align="left">The fare difference between a ride in a red taxi and a yellow taxi.</td>
<td align="left">The fare difference between a ride in a red taxi and a yellow taxi.</td>
</tr>
</tbody>
</table>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-78-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="centered-predictors" class="section level2">
<h2><span class="header-section-number">4.4</span> Centered predictors</h2>
<ul>
<li><p>Now let’s imagine that I don’t know if the number of passengers affects the fare. So far I’ve been riding alone. Now let’s look at a few rides with several other people (<span class="math inline">\(distance = 10~km\)</span>, <span class="math inline">\(N_{bridges} = 0\)</span>, yellow cabs only).</p></li>
<li><p>As previously, we will model the relationship with a linear equation:</p>
<p><span class="math display">\[ \text{fare} = a + b * \text{number of passengers} \]</span></p></li>
<li><p>However if we model it like this, our intercept is 24 as you see in the plot below, and not 29, as we would expect. We did travel 10 km, after all. - Why is the fare so low?</p></li>
<li><p>The reason is that the intercept is the value of the fare when <strong>all</strong> predictors are 0 - yes, even the number of passengers. Barring any extremely unusual situations, this is not actually possible, and therefore an intercept of this kind is really just a number we need to plug into the equation. In other words, we don’t learn anything from it.</p></li>
<li><p>In order to remedy the situation and obtain a more useful intercept, we can <strong>center</strong> the predictor - that is, subtract the average of the vector from the vector itself. In this case, since the average number of passengers is <span class="math inline">\(2.5\)</span>, we will use</p></li>
</ul>
<p><span class="math display">\[\text{fare} = a + b * (\text{number of passengers}-2.5)\]</span></p>
<ul>
<li>This will leave us with the following interpretations of the coefficients:
<ul>
<li><span class="math inline">\(a\)</span>: the fare paid for the average number of passengers, in this case for 2.5 passengers (on a 10 km ride, crossing 0 bridges, in a yellow cab)</li>
<li><span class="math inline">\(b\)</span>: the additional fare for every additional passenger (on a 10 km ride, crossing 0 bridges, in a yellow cab)</li>
</ul></li>
</ul>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-79-1.png" width="960" style="display: block; margin: auto;" /></p>
<ul>
<li><p>As you see, centering the predictor in a single-variable model changes the meaning of the intercept. As you can verify in the above plot, centering makes the intercept correspond to the cab fare at the <em>average number of passengers</em> (instead of <em>at zero passengers</em>).
This change in interpretation is because centering changes the interpretation of the zero point of the predictor. While zero corresponds to <em>no passengers</em> when the predictor for the number of passengers is uncentered, it corresponds to the average number of passengers when it is centerered. The data is “moved to the left”, so to say. Because the intercept corresponds to the value of the fare at zero, the intercept changes as a result of centering.</p></li>
<li><p>In sum, centering predictors in single-variable models can help obtain interpretable coefficients.</p></li>
</ul>
<!-- In all these sections, I never actually tell how I arrive at the model estimates. I should probably mention this in a few words somewhere at the beginning of section 2. -->
</div>
<div id="main-effects-and-interactions" class="section level2">
<h2><span class="header-section-number">4.5</span> Main effects and interactions</h2>
<ul>
<li><p>Let’s take a look the effect of cab color and cab size. What I didn’t mention before is that cabs come in two different sizes: 5-seaters, and 9-seaters. I want to find out whether larger cabs cost more. We’ll be looking at a subset of data with <span class="math inline">\(distance = 10~km\)</span>, and <span class="math inline">\(N_{bridges}=0\)</span>, only day rides.</p></li>
<li><p>We will set up numerical contrasts for the predictors for cab color (yellow and red), and cab size (5-seaters and 9-seaters), and model the relationship with the following linear equation. This means that we are trying to estimate the (main) effects of cab color and size, and maybe something else.</p></li>
<li><p>As previously, I would like to model the relationship using two additive terms, one for color, one for size.<br />
<span class="math display" id="eq:interactions1">\[\begin{equation} 
\text{fare} = a + b_1 * \text{cCabColorRed} + b_2 * \text{cCabSize9Seater} 
\tag{4.2}
\end{equation}\]</span></p></li>
<li>Let’s see if that’s possible. Here is a plot of the data along with connecting lines (not a model, just lines).</li>
<li><p>This is weird … the effect of size depends on cab color. (You can see that the lines aren’t parallel, which means that the distance between them changes as x changes.)
<img src="LectureNotes_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p></li>
<li><p>Here is the raw data. So, can we model the relationship using equation <a href="errorless_lms.html#eq:interactions1">(4.2)</a>?</p></li>
</ul>
<pre><code>##      cab_color_red cab_size_9seater fare_mnt
## 1126             0                1       44
## 4113             0                0       29
## 5832             1                0       39
## 9756             1                1       59</code></pre>
<ul>
<li>Of course not, because we need to account for the fact that the effect of color <em>depends</em> on size. In other words, there is an <strong>interaction</strong> <em>between color and size</em>.</li>
<li><p>As you see, no additive model will describe the relationship correctly.
<img src="LectureNotes_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p></li>
<li>Luckily, it’s only one point that is usually off. So what we need, is to ‘bump up’ the value at <span class="math inline">\(size=1, color=1\)</span>.</li>
<li><p>We can do this by creating a new predictor from the old ones, and giving it its own slope:</p></li>
</ul>
<pre><code>##      cab_color_red cab_size_9seater cab_color_red__by__cab_size_9seater
## 1126             0                1                                   0
## 4113             0                0                                   0
## 5832             1                0                                   0
## 9756             1                1                                   1
##      fare_mnt
## 1126       44
## 4113       29
## 5832       39
## 9756       59</code></pre>
<ul>
<li><p>The new model, which includes two <strong>‘main effects’</strong> and an <strong>‘interaction’</strong> between them becomes:<br />
<span class="math display" id="eq:interactions2">\[\begin{equation} 
\text{fare} = a + b_1 * \text{cCabColorRed} + \\ b_2 * \text{cCabSize9Seater} + \\ b_3 * \text{cCabColorRed} * \text{cCabSize9Seater}
\tag{4.3}
\end{equation}\]</span></p></li>
<li>In this model, 5 is added to the prediction when <em>both</em> size, and color equal 1.</li>
<li><p>Such interactions also work quite well for continuous predictors, but that’s for another time …</p></li>
</ul>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
<!-- to-do: Add a 3D explanation with a plane -->
<!-- to-do: 
## Interactions between continuous predictors. 
-->
</div>
<div id="centered-predictors-and-their-effect-on-main-effect-and-interaction-coefficients" class="section level2">
<h2><span class="header-section-number">4.6</span> Centered predictors and their effect on main effect and interaction coefficients</h2>
<ul>
<li>We will set up numerical contrasts for the predictors for cab color (yellow and red), and cab size (5-seaters and 9-seaters), and model the relationship with the following linear equation. This means that we are trying to estimate the main effects of cab color and size, as well as their interaction.</li>
</ul>
<p><span class="math display">\[ \text{fare} = a + b_1 * \text{cCabColorRed} + b_2 * \text{cCabSize9Seater} + b_3 * \text{cCabColorRed} * \text{cCabSize9Seater}  \]</span></p>
<ul>
<li>We can treat the predictors in one of two ways<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>: We can either encode them using <em>treatment contrasts</em> (<span class="math inline">\(0/1\)</span>), or using <em>sum contrasts</em> (<span class="math inline">\(-.5/+.5\)</span>). Let’s review in turn what happens when we use each of those contrast coding schemes.</li>
</ul>
<!-- The plots below illustrate the relationship between the numerical contrasts and cab fare. -->
<div id="treatment-contrasts" class="section level3">
<h3><span class="header-section-number">4.6.1</span> Treatment Contrasts</h3>
<ul>
<li>If we use treatment contrasts, the combinations of our predictors can be reduced to the four unique cases below.
<ul>
<li>The first three columns indicate the encoding of the color contrast (yellow=0, red=1) and size contrast (5-seater=0, 9-seater=1), and the interaction predictor (the product of the previous two).</li>
<li>The next column illustrates what happens when we plug these predictors into the equation above. In other words, it shows how we can construct the predicted fare from the coefficients of the linear model.</li>
<li>Finally, the last column illustrates the simplified version of the predicted value of the fare, with all terms which equal zero removed.</li>
</ul></li>
<li>This table below illustrates that:
<ul>
<li>The intercept <span class="math inline">\(a\)</span> corresponds to the fare for yellow 5-seaters (it is the only non-zero term in row (1a)).</li>
<li>The slope <span class="math inline">\(b_1\)</span> corresponds to the <em>effect of color for 5-seaters only</em> (it is the difference between rows (1c) and (1a)).</li>
<li>The slope <span class="math inline">\(b_2\)</span> corresponds to the <em>effect of size for yellow cabs only</em> (it is the difference between rows (1b) and (1a)).</li>
<li>The slope <span class="math inline">\(b_3\)</span> corresponds to the <strong>additional</strong> <em>effect of size for red cabs</em>. Alternatively, it can be understood as the <strong>additional</strong> <em>effect of color for 9-seaters</em>.</li>
</ul></li>
</ul>
<!-- Isn't there a good way to illustrate it with a difference? -->
<p>(In understanding the above reasoning it may help not to focus on how <span class="math inline">\(a,b_1,b_2\)</span> and <span class="math inline">\(b_3\)</span> are obtained, but rather focus on how <span class="math inline">\(a,b_1,b_2\)</span> and <span class="math inline">\(b_3\)</span> would behave in the above equations if they corresponded to the meaning I assigned them.)</p>
<table>
<colgroup>
<col width="19%" />
<col width="19%" />
<col width="23%" />
<col width="7%" />
<col width="7%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">color</th>
<th align="left">size</th>
<th align="left">color <span class="math inline">\(\cdot\)</span> size</th>
<th align="left"></th>
<th align="left"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><em>(1a)</em></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(fare = a + 0 \cdot b_1 + 0 \cdot b_2 + 0 \cdot b_3\)</span></td>
<td align="left"><span class="math inline">\(= a\)</span></td>
</tr>
<tr class="even">
<td align="left"><em>(1b)</em></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(fare = a + 0 \cdot b_1 + 1 \cdot b_2 + 0 \cdot b_3\)</span></td>
<td align="left"><span class="math inline">\(= a + b_2\)</span></td>
</tr>
<tr class="odd">
<td align="left"><em>(1c)</em></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(fare = a + 1 \cdot b_1 + 0 \cdot b_2 + 0 \cdot b_3\)</span></td>
<td align="left"><span class="math inline">\(= a + b_1\)</span></td>
</tr>
<tr class="even">
<td align="left"><em>(1d)</em></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(fare = a + 1 \cdot b_1 + 1 \cdot b_2 + 1 \cdot b_3\)</span></td>
<td align="left"><span class="math inline">\(= a + b_1 + b_2 + b_3\)</span></td>
</tr>
</tbody>
</table>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-86-1.png" width="960" /></p>
</div>
<div id="centered-contrasts-aka-sum-contrasts" class="section level3">
<h3><span class="header-section-number">4.6.2</span> Centered Contrasts (aka Sum Contrasts)</h3>
<ul>
<li>One of the problems with the above coefficient interpretations is that in most cases they are not quite what we are looking for.</li>
<li>In most cases, we’ll be interested in the average effect of cab color, the average effect of cab size, and the interaction between the two, and <strong>not</strong> in the effect of color for small cabs, the effect size for yellow cabs, and the interaction between the two.</li>
<li>While we can compute one set of coefficients from the other, the former are far more informative.</li>
<li>Why would you want to invest several hours into learning how to do this with a linear model? (Because it’ll save you <strong>a lot</strong> of headaches later on.)</li>
<li><p>In trying to understand how these contrasts work, please focus on what properties they have rather than on how I (or someone) came up with them.</p></li>
<li>Using sum contrasts will give us more informative coefficients. The table below also illustrates that:
<ul>
<li><strong>The intercept <span class="math inline">\(a\)</span></strong> corresponds to the <strong>average</strong> <em>fare</em> in the data set (the average of the rows (2a-d) is <span class="math inline">\(a\)</span>).</li>
<li><strong>The slope <span class="math inline">\(b_1\)</span></strong> corresponds to the <strong>average</strong> <em>effect of size</em> (the average of (2a,b) minus the average of (2c,d) is <span class="math inline">\(b_1\)</span>).</li>
<li><strong>The slope <span class="math inline">\(b_2\)</span></strong> corresponds to the <strong>average</strong> <em>effect of color</em> (the average of (2a,c) minus the average of (2b,d) is <span class="math inline">\(b_2\)</span>).</li>
<li><strong>The slope <span class="math inline">\(b_3\)</span></strong> corresponds to the <strong>additional</strong> <em>effect of size for red cabs</em>. Alternatively, it can be understood as the <strong>additional</strong> <em>effect of color for 9-seaters</em>.</li>
</ul></li>
</ul>
<!-- Isn't there a good way to illustrate it with a difference? -->
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">color</th>
<th align="left">size</th>
<th align="left">color <span class="math inline">\(\cdot\)</span> size</th>
<th align="left"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><em>(2a)</em></td>
<td align="left"><span class="math inline">\(-.5\)</span></td>
<td align="left"><span class="math inline">\(-.5\)</span></td>
<td align="left"><span class="math inline">\(+.25\)</span></td>
<td align="left"><span class="math inline">\(fare = a - .5 \cdot b_1 - .5 \cdot b_2 + .25 \cdot b_3\)</span></td>
</tr>
<tr class="even">
<td align="left"><em>(2b)</em></td>
<td align="left"><span class="math inline">\(-.5\)</span></td>
<td align="left"><span class="math inline">\(+.5\)</span></td>
<td align="left"><span class="math inline">\(-.25\)</span></td>
<td align="left"><span class="math inline">\(fare = a - .5 \cdot b_1 + .5 \cdot b_2 - .25 \cdot b_3\)</span></td>
</tr>
<tr class="odd">
<td align="left"><em>(2c)</em></td>
<td align="left"><span class="math inline">\(+.5\)</span></td>
<td align="left"><span class="math inline">\(-.5\)</span></td>
<td align="left"><span class="math inline">\(-.25\)</span></td>
<td align="left"><span class="math inline">\(fare = a + .5 \cdot b_1 - .5 \cdot b_2 - .25 \cdot b_3\)</span></td>
</tr>
<tr class="even">
<td align="left"><em>(2d)</em></td>
<td align="left"><span class="math inline">\(+.5\)</span></td>
<td align="left"><span class="math inline">\(+.5\)</span></td>
<td align="left"><span class="math inline">\(+.25\)</span></td>
<td align="left"><span class="math inline">\(fare = a + .5 \cdot b_1 + .5 \cdot b_2 + .25 \cdot b_3\)</span></td>
</tr>
</tbody>
</table>
<!-- to-do:
- Let's look at some averages

  |      | color | size | color $\cdot$ size |      |
  |:-----|:------|:-----|:-------|:-----|
  |*(2a)*|$-.5$  | $-.5$| $+.25$ | $fare = a - .5 \cdot b_1  - .5 \cdot b_2 + .25 \cdot b_3$ | 
  |*(2b)*|$-.5$  | $+.5$| $-.25$ | $fare = a - .5 \cdot b_1  + .5 \cdot b_2 - .25 \cdot b_3$ | 
  |*(2c)*|$+.5$  | $-.5$| $-.25$ | $fare = a + .5 \cdot b_1  - .5 \cdot b_2 - .25 \cdot b_3$ |
  |*(2d)*|$+.5$  | $+.5$| $+.25$ | $fare = a + .5 \cdot b_1  + .5 \cdot b_2 + .25 \cdot b_3$ |
-->
<!-- to-do: This really calls for a 3D visualization -->
<!-- to-do: Choose a bigger interaction next time. It's barely visible. -->
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-87-1.png" width="1440" /></p>
<!--
TODO: Review these combinations in an optional subsection

color centered

|     | color | size | color $\cdot$ size |
  |:----|:------|:-----|:-|:-----|:--|
  |     |$-.5$  | $0$  | $0$   |$fare = a - .5 \cdot b_1 + 0 \cdot b_2 + 0 \cdot b_3$ | 
  |     |$-.5$  | $1$  | $-.5$ |$fare = a - .5 \cdot b_1 + 1 \cdot b_2 + 0 \cdot b_3$ | 
  |     |$+.5$  | $0$  | $0$   |$fare = a + .5 \cdot b_1 + 0 \cdot b_2 + 0 \cdot b_3$ | 
  |     |$+.5$  | $1$  | $+.5$ |$fare = a + .5 \cdot b_1 + 1 \cdot b_2 + .5 \cdot b_3$ |
  
  
  size centered

|     | color | size | color $\cdot$ size |
  |:----|:----|:-----|:---|:-----|
  |     |$0$  | $-.5$| $0$ |$fare = a + 0 \cdot b_1  - .5 \cdot b_2$ |
  |     |$0$  | $+.5$| $0$ |$fare = a + 0 \cdot b_1  + .5 \cdot b_2$ |
  |     |$1$  | $-.5$| $-.5$ |$fare = a + 1 \cdot b_1  - .5 \cdot b_2$ |
  |     |$1$  | $+.5$| $+.5$ |$fare = a + 1 \cdot b_1  + .5 \cdot b_2$ | 
  -->
<!--
# Deterministic Generalized Linear Models

Introduce generalized linear models with an example that where a predictor has a multiplicative effect on probabilities. Discuss that it's very implausible for anything to have an additive effect on probabilities.
The ultimate model should still be deterministic.
-->

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>Please note that we don’t neeed to assume that the <em>‘true relationship’</em> between the two variables is actually linear. Most interesting relationships are not linear. However, we can still learn a lot about them from a linear model as you will see in the following, especially if we are willing to assume that they are <strong>approximately linear</strong>.
<!-- to-do: In the following, sprinkle in sections about what we can still learn even if the relationship is not actually linear. --><a href="errorless_lms.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>While the number of bridges depends on distance, it is in principle possible to cross a bridge while keeping the travel distance below a kilometer, in which case it would count as zero.<a href="errorless_lms.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>Please note that it is the average of the two fares, and <strong>not</strong> the average fare. <!-- Explain how they are different --><a href="errorless_lms.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>There are more ways to encode the predictors, but these are the most common ones.<a href="errorless_lms.html#fnref7" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="descriptives.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lms_with_error.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["LectureNotes.pdf", "LectureNotes.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
