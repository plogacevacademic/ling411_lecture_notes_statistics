<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Statistical Models II | Statistics in R</title>
  <meta name="description" content="Chapter 9 Statistical Models II | Statistics in R" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Statistical Models II | Statistics in R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Statistical Models II | Statistics in R" />
  
  
  

<meta name="author" content="Pavel Logacev" />


<meta name="date" content="2021-02-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="statistical-models.html"/>
<link rel="next" href="case-studies.html"/>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.17/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<script src="libs/rglWebGL-binding-0.103.5/rglWebGL.js"></script>
<link href="libs/rglwidgetClass-0.103.5/rgl.css" rel="stylesheet" />
<script src="libs/rglwidgetClass-0.103.5/rglClass.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/utils.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/subscenes.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/shaders.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/textures.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/projection.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/mouse.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/init.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/pieces.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/draw.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/controls.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/selection.src.js"></script>
<script src="libs/rglwidgetClass-0.103.5/rglTimer.src.js"></script>
<script src="libs/CanvasMatrix4-0.103.5/CanvasMatrix.src.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Initial Remarks</a></li>
<li class="chapter" data-level="2" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html"><i class="fa fa-check"></i><b>2</b> Scales of Measurement</a><ul>
<li class="chapter" data-level="2.1" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#nominal-scale"><i class="fa fa-check"></i><b>2.1</b> Nominal scale</a></li>
<li class="chapter" data-level="2.2" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#ordinal-scale"><i class="fa fa-check"></i><b>2.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="2.3" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#interval-scale"><i class="fa fa-check"></i><b>2.3</b> Interval scale</a></li>
<li class="chapter" data-level="2.4" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#ratio-scale"><i class="fa fa-check"></i><b>2.4</b> Ratio scale</a></li>
<li class="chapter" data-level="2.5" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#continuous-versus-discrete-variables"><i class="fa fa-check"></i><b>2.5</b> Continuous versus discrete variables</a></li>
<li class="chapter" data-level="2.6" data-path="scalesOfMeasurement.html"><a href="scalesOfMeasurement.html#some-complexities"><i class="fa fa-check"></i><b>2.6</b> Some complexities</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>3</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="3.1" data-path="descriptives.html"><a href="descriptives.html#centraltendency"><i class="fa fa-check"></i><b>3.1</b> Measures of central tendency</a><ul>
<li class="chapter" data-level="3.1.1" data-path="descriptives.html"><a href="descriptives.html#mean"><i class="fa fa-check"></i><b>3.1.1</b> The mean</a></li>
<li class="chapter" data-level="3.1.2" data-path="descriptives.html"><a href="descriptives.html#calculating-the-mean-in-r"><i class="fa fa-check"></i><b>3.1.2</b> Calculating the mean in R</a></li>
<li class="chapter" data-level="3.1.3" data-path="descriptives.html"><a href="descriptives.html#median"><i class="fa fa-check"></i><b>3.1.3</b> The median</a></li>
<li class="chapter" data-level="3.1.4" data-path="descriptives.html"><a href="descriptives.html#mean-or-median-whats-the-difference"><i class="fa fa-check"></i><b>3.1.4</b> Mean or median? What’s the difference?</a></li>
<li class="chapter" data-level="3.1.5" data-path="descriptives.html"><a href="descriptives.html#trimmedmean"><i class="fa fa-check"></i><b>3.1.5</b> Trimmed mean</a></li>
<li class="chapter" data-level="3.1.6" data-path="descriptives.html"><a href="descriptives.html#mode"><i class="fa fa-check"></i><b>3.1.6</b> Mode</a></li>
<li class="chapter" data-level="3.1.7" data-path="descriptives.html"><a href="descriptives.html#summary"><i class="fa fa-check"></i><b>3.1.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="descriptives.html"><a href="descriptives.html#var"><i class="fa fa-check"></i><b>3.2</b> Measures of variability</a><ul>
<li class="chapter" data-level="3.2.1" data-path="descriptives.html"><a href="descriptives.html#range"><i class="fa fa-check"></i><b>3.2.1</b> Range</a></li>
<li class="chapter" data-level="3.2.2" data-path="descriptives.html"><a href="descriptives.html#quantiles-and-percentile"><i class="fa fa-check"></i><b>3.2.2</b> Quantiles and percentile</a></li>
<li class="chapter" data-level="3.2.3" data-path="descriptives.html"><a href="descriptives.html#interquartile-range"><i class="fa fa-check"></i><b>3.2.3</b> Interquartile range</a></li>
<li class="chapter" data-level="3.2.4" data-path="descriptives.html"><a href="descriptives.html#aad"><i class="fa fa-check"></i><b>3.2.4</b> Mean absolute deviation</a></li>
<li class="chapter" data-level="3.2.5" data-path="descriptives.html"><a href="descriptives.html#variance"><i class="fa fa-check"></i><b>3.2.5</b> Variance</a></li>
<li class="chapter" data-level="3.2.6" data-path="descriptives.html"><a href="descriptives.html#sd"><i class="fa fa-check"></i><b>3.2.6</b> Standard deviation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="errorless-lms.html"><a href="errorless-lms.html"><i class="fa fa-check"></i><b>4</b> Error-less Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="errorless-lms.html"><a href="errorless-lms.html#single-variable-models"><i class="fa fa-check"></i><b>4.1</b> Single-variable models</a></li>
<li class="chapter" data-level="4.2" data-path="errorless-lms.html"><a href="errorless-lms.html#multi-variable-models"><i class="fa fa-check"></i><b>4.2</b> Multi-variable models</a></li>
<li class="chapter" data-level="4.3" data-path="errorless-lms.html"><a href="errorless-lms.html#models-with-categorical-predictors"><i class="fa fa-check"></i><b>4.3</b> Models with categorical predictors</a></li>
<li class="chapter" data-level="4.4" data-path="errorless-lms.html"><a href="errorless-lms.html#centered-predictors"><i class="fa fa-check"></i><b>4.4</b> Centered predictors</a></li>
<li class="chapter" data-level="4.5" data-path="errorless-lms.html"><a href="errorless-lms.html#main-effects-and-interactions"><i class="fa fa-check"></i><b>4.5</b> Main effects and interactions</a></li>
<li class="chapter" data-level="4.6" data-path="errorless-lms.html"><a href="errorless-lms.html#centered-predictors-and-their-effect-on-main-effect-and-interaction-coefficients"><i class="fa fa-check"></i><b>4.6</b> Centered predictors and their effect on main effect and interaction coefficients</a><ul>
<li class="chapter" data-level="4.6.1" data-path="errorless-lms.html"><a href="errorless-lms.html#treatment-contrasts"><i class="fa fa-check"></i><b>4.6.1</b> Treatment Contrasts</a></li>
<li class="chapter" data-level="4.6.2" data-path="errorless-lms.html"><a href="errorless-lms.html#centered-contrasts-aka-sum-contrasts"><i class="fa fa-check"></i><b>4.6.2</b> Centered Contrasts (aka Sum Contrasts)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lms-with-error.html"><a href="lms-with-error.html"><i class="fa fa-check"></i><b>5</b> Linear Models With Error</a><ul>
<li class="chapter" data-level="5.1" data-path="lms-with-error.html"><a href="lms-with-error.html#a-whole-zoo-of-models"><i class="fa fa-check"></i><b>5.1</b> A Whole Zoo of Models</a></li>
<li class="chapter" data-level="5.2" data-path="lms-with-error.html"><a href="lms-with-error.html#an-updated-linear-model"><i class="fa fa-check"></i><b>5.2</b> An Updated Linear Model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="examples.html"><a href="examples.html"><i class="fa fa-check"></i><b>6</b> Examples</a><ul>
<li class="chapter" data-level="6.1" data-path="examples.html"><a href="examples.html#the-dative-verbs-data"><i class="fa fa-check"></i><b>6.1</b> The Dative Verbs Data</a><ul>
<li class="chapter" data-level="6.1.1" data-path="examples.html"><a href="examples.html#by-length-of-recipient"><i class="fa fa-check"></i><b>6.1.1</b> By Length of Recipient</a></li>
<li class="chapter" data-level="6.1.2" data-path="examples.html"><a href="examples.html#by-length-of-theme"><i class="fa fa-check"></i><b>6.1.2</b> By Length of Theme</a></li>
<li class="chapter" data-level="6.1.3" data-path="examples.html"><a href="examples.html#by-length-of-recipient-and-length-of-theme"><i class="fa fa-check"></i><b>6.1.3</b> By Length of Recipient and Length of Theme</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html"><i class="fa fa-check"></i><b>7</b> Samples, Populations and Probability</a><ul>
<li class="chapter" data-level="7.1" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#the-dative-verbs-data-revisited"><i class="fa fa-check"></i><b>7.1</b> The Dative Verbs Data Revisited</a></li>
<li class="chapter" data-level="7.2" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#populations-and-samples"><i class="fa fa-check"></i><b>7.2</b> Populations and Samples</a><ul>
<li class="chapter" data-level="7.2.1" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#examples-1"><i class="fa fa-check"></i><b>7.2.1</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#the-role-of-statistical-models"><i class="fa fa-check"></i><b>7.3</b> The Role of Statistical Models</a></li>
<li class="chapter" data-level="7.4" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#probability"><i class="fa fa-check"></i><b>7.4</b> Probability</a><ul>
<li class="chapter" data-level="7.4.1" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#examples-of-probabilistic-statments"><i class="fa fa-check"></i><b>7.4.1</b> Examples of Probabilistic Statments</a></li>
<li class="chapter" data-level="7.4.2" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#the-notion-of-probability"><i class="fa fa-check"></i><b>7.4.2</b> The Notion of Probability</a></li>
<li class="chapter" data-level="7.4.3" data-path="samples-populations-and-probability.html"><a href="samples-populations-and-probability.html#the-laws-of-probability"><i class="fa fa-check"></i><b>7.4.3</b> The Laws of Probability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="statistical-models.html"><a href="statistical-models.html"><i class="fa fa-check"></i><b>8</b> Statistical Models</a><ul>
<li class="chapter" data-level="8.0.1" data-path="statistical-models.html"><a href="statistical-models.html#a-first-statistical-model"><i class="fa fa-check"></i><b>8.0.1</b> A First Statistical Model</a></li>
<li class="chapter" data-level="8.1" data-path="statistical-models.html"><a href="statistical-models.html#log-likelihood-and-numerical-underflow"><i class="fa fa-check"></i><b>8.1</b> Log-likelihood and numerical underflow</a><ul>
<li class="chapter" data-level="8.1.1" data-path="statistical-models.html"><a href="statistical-models.html#logarithm"><i class="fa fa-check"></i><b>8.1.1</b> Logarithm</a></li>
<li class="chapter" data-level="8.1.2" data-path="statistical-models.html"><a href="statistical-models.html#log-likelihood"><i class="fa fa-check"></i><b>8.1.2</b> Log-likelihood</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html"><i class="fa fa-check"></i><b>9</b> Statistical Models II</a><ul>
<li class="chapter" data-level="9.0.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#example-1"><i class="fa fa-check"></i><b>9.0.1</b> Example 1</a></li>
<li class="chapter" data-level="9.0.2" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#example-2"><i class="fa fa-check"></i><b>9.0.2</b> Example 2</a></li>
<li class="chapter" data-level="9.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#probability-distributions"><i class="fa fa-check"></i><b>9.1</b> Probability Distributions</a><ul>
<li class="chapter" data-level="9.1.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#bernoulli-distribution"><i class="fa fa-check"></i><b>9.1.1</b> Bernoulli Distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#binomial-distribution"><i class="fa fa-check"></i><b>9.2</b> Binomial Distribution</a><ul>
<li class="chapter" data-level="9.2.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#gaussian-distribution-normal-distribution"><i class="fa fa-check"></i><b>9.2.1</b> Gaussian Distribution (‘Normal Distribution’)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#a-likelihood-function-for-the-vaccine-data"><i class="fa fa-check"></i><b>9.3</b> A likelihood function for the vaccine data</a></li>
<li class="chapter" data-level="9.4" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#bayesian-inference-i"><i class="fa fa-check"></i><b>9.4</b> Bayesian Inference I</a></li>
<li class="chapter" data-level="9.5" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#returning-to-example-1"><i class="fa fa-check"></i><b>9.5</b> Returning to Example 1</a><ul>
<li class="chapter" data-level="9.5.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#likelihood"><i class="fa fa-check"></i><b>9.5.1</b> Likelihood</a></li>
<li class="chapter" data-level="9.5.2" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#prior"><i class="fa fa-check"></i><b>9.5.2</b> Prior</a></li>
<li class="chapter" data-level="9.5.3" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#marginal-probability-of-the-data"><i class="fa fa-check"></i><b>9.5.3</b> Marginal probability of the data</a></li>
<li class="chapter" data-level="9.5.4" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#posterior-probability"><i class="fa fa-check"></i><b>9.5.4</b> Posterior probability</a></li>
<li class="chapter" data-level="9.5.5" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#and-now-again-for"><i class="fa fa-check"></i><b>9.5.5</b> And now again, for</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#bayesian-inference-ii"><i class="fa fa-check"></i><b>9.6</b> Bayesian Inference II</a></li>
<li class="chapter" data-level="9.7" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#back-to-our-incidence-rates"><i class="fa fa-check"></i><b>9.7</b> Back to our incidence rates</a><ul>
<li class="chapter" data-level="9.7.1" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#brazil"><i class="fa fa-check"></i><b>9.7.1</b> Brazil</a></li>
<li class="chapter" data-level="9.7.2" data-path="statistical-models-ii.html"><a href="statistical-models-ii.html#turkey"><i class="fa fa-check"></i><b>9.7.2</b> Turkey</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="case-studies.html"><a href="case-studies.html"><i class="fa fa-check"></i><b>10</b> Case Studies</a><ul>
<li class="chapter" data-level="10.1" data-path="case-studies.html"><a href="case-studies.html#vot-data"><i class="fa fa-check"></i><b>10.1</b> VOT Data</a><ul>
<li class="chapter" data-level="10.1.1" data-path="case-studies.html"><a href="case-studies.html#loading-the-data"><i class="fa fa-check"></i><b>10.1.1</b> Loading the Data</a></li>
<li class="chapter" data-level="10.1.2" data-path="case-studies.html"><a href="case-studies.html#explorotary-data-analysis-and-descriptive-statistics"><i class="fa fa-check"></i><b>10.1.2</b> Explorotary Data Analysis and Descriptive Statistics</a></li>
<li class="chapter" data-level="10.1.3" data-path="case-studies.html"><a href="case-studies.html#how-long-is-the-difference-between-voiced-and-unvoiced-stops-in-english-and-in-korean"><i class="fa fa-check"></i><b>10.1.3</b> How long is the difference between voiced and unvoiced stops in English and in Korean?</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="case-studies.html"><a href="case-studies.html#priming-experiment"><i class="fa fa-check"></i><b>10.2</b> Priming Experiment</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="your-term-paper.html"><a href="your-term-paper.html"><i class="fa fa-check"></i><b>11</b> Your term paper</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistical-models-ii" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Statistical Models II</h1>
<ul>
<li>Sometimes we have data in a format that doesn’t allow us a to formulate a generative model that goes <em>all the way</em>.</li>
</ul>
<div id="example-1" class="section level3">
<h3><span class="header-section-number">9.0.1</span> Example 1</h3>
<ul>
<li>For example here is data from two SinoVac phase-III trials (for the ‘CoronaVac’ vaccine). [Data: Jan 15, 2021]</li>
</ul>
<table>
<colgroup>
<col width="13%" />
<col width="10%" />
<col width="22%" />
<col width="17%" />
<col width="17%" />
<col width="17%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">country</th>
<th align="left">group</th>
<th align="left">total participants</th>
<th align="left">COVID-19 cases</th>
<th align="left">incidence (<strong>estimated</strong> rate)</th>
<th align="left"><strong>estimated</strong> vaccine efficacy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Brazil</td>
<td align="left">placebo</td>
<td align="left">~6500</td>
<td align="left">167</td>
<td align="left">~0.026</td>
<td align="left">~0.5 <span class="math inline">\((1-0.013/0.026)\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">vaccine</td>
<td align="left">~6500</td>
<td align="left">85</td>
<td align="left">~0.013</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Turkey</td>
<td align="left">placebo</td>
<td align="left">570</td>
<td align="left">26</td>
<td align="left">~0.046</td>
<td align="left">~0.913 <span class="math inline">\((1-0.004/0.046)\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">vaccine</td>
<td align="left">752</td>
<td align="left">3</td>
<td align="left">~0.004</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<ul>
<li><p>FYI: The vaccine efficacy is <em>‘is the percentage reduction of disease in a vaccinated group of people compared to an unvaccinated group’</em>, we will calculate it as <span class="math inline">\(1-incidence_{vaccine}/incidence_{placebo}\)</span> for the present purposes.</p></li>
<li><p>I’d like to model it similarly to our dative model, as below. (Keep in mind, this is not a mechanistic model of infection, but a statistical model. A lens through which we choose to look at the data.)</p></li>
</ul>
<div class="figure"><span id="fig:illustrationModel2"></span>
<img src="img/infectionmodel.jpeg" alt="A schematic of the infection model." height="300" />
<p class="caption">Figure 9.1: A schematic of the infection model.</p>
</div>
<ul>
<li><p>Our estimate of the vaccine efficacy would be <span class="math inline">\(eff = 1-p_2/p_1\)</span>.</p></li>
<li>So how do we compute the likelihood of each data point given the parameters?</li>
<li>In the dative data set, our data points were 0s and 1s. Each corresponded to a single observation.</li>
<li>Here, our observations are <em>aggregates</em> (i.e., 26 out of 570). That’s a bit different.</li>
<li>We could make up a data set with <em>‘single observations’</em> that matches this statistic, and it will work in many cases, but not always.</li>
<li><p>There is a better solution, though.</p></li>
</ul>
</div>
<div id="example-2" class="section level3">
<h3><span class="header-section-number">9.0.2</span> Example 2</h3>
<ul>
<li>The mammalian sleep data set. How do we model the number of hours animals sleep?</li>
</ul>
<pre><code>##  [1] 12 17 14 15  4 14  9  7 10  3  5  9 10 12 10  8  9 17  5 18  4 20  3  3 10
## [26] 11 15 12 10  2  3  6  6  8 10  3 19 10 14 14 13 12 20 15 11  8 14  8  4 10
## [51] 16 10 14  9 10 11 12 14  4  6 11 18  5 13  9 10  8 11 11 17 14 16 13  9  9
## [76] 16  4 16  9  5  6 12 10</code></pre>
<ul>
<li>No idea. But we have to do it somehow, right?</li>
</ul>
</div>
<div id="probability-distributions" class="section level2">
<h2><span class="header-section-number">9.1</span> Probability Distributions</h2>
<ul>
<li>Luckily, our problems are not unique, and very cool solutions have been developed.</li>
<li><p>For many problems, it has been worked out what the probability distributions of some common generative processes are.</p></li>
<li>A <strong>probability distribution</strong> is an assignment of probabilites to events (i.e., an assignment of numbers such that it follows the laws of probability).</li>
<li><p>A probability distribution with discrete outcomes can be characterized by its <strong>probability mass function (PMF)</strong>.</p></li>
<li>Example: I could describe the outcomes of an experiment where I take one marble from a bag with one blue and three marbles with either of the following ditributions, depending on whether I’m interested in the particular marbles identity, or just their color:
<ul>
<li>Distribution 1:<br />
<span class="math inline">\(P(marble~1~[blue] ) = 0.25\)</span><br />
<span class="math inline">\(P(marble~2~[white]) = 0.25\)</span><br />
<span class="math inline">\(P(marble~3~[white]) = 0.25\)</span><br />
<span class="math inline">\(P(marble~4~[white]) = 0.25\)</span></li>
<li>Distribution 2:<br />
<span class="math inline">\(P(blue~marble~[1]) = 0.25~~~~~~~~~~~\)</span><br />
<span class="math inline">\(P(white~marble~[2,3,~or~4]) = 0.75\)</span></li>
</ul></li>
</ul>
<div id="bernoulli-distribution" class="section level3">
<h3><span class="header-section-number">9.1.1</span> Bernoulli Distribution</h3>
<ul>
<li><p>Below is the probability mass function for a <strong>Bernoulli distribution</strong> with the parameter <span class="math inline">\(p=.6\)</span>.</p></li>
<li><p>Generative process assumed by the <strong>Bernoulli distribution</strong>: a single <em>“trial”</em> which can result in either<em>“success”</em> or <em>“failure”</em>.</p></li>
</ul>
<div class="figure"><span id="fig:illustrationModel3"></span>
<img src="img/bernoulliProcess.jpeg" alt="A schematic of the infection model." height="100" />
<p class="caption">Figure 9.2: A schematic of the infection model.</p>
</div>
<ul>
<li>Examples: coin flip (H/T), drawing <em>one</em> marble (W/B), shooting (H/M)</li>
</ul>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" title="1"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb118-2" title="2">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">successes =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>, <span class="dt">prob =</span> <span class="kw">dbinom</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">prob =</span> <span class="fl">.6</span>) )</a>
<a class="sourceLine" id="cb118-3" title="3"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(successes, prob)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="dt">width =</span> <span class="fl">0.1</span>)<span class="op">+</span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st">&quot;Bernoulli Distribution (p=.6)&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-136-1.png" width="672" /></p>
</div>
</div>
<div id="binomial-distribution" class="section level2">
<h2><span class="header-section-number">9.2</span> Binomial Distribution</h2>
<ul>
<li>Generative process assumed by the <strong>binomial distribution</strong>: <span class="math inline">\(n\)</span> trials with a fixed probability <span class="math inline">\(p\)</span> of success. We count the number of successes.</li>
</ul>
<div class="figure"><span id="fig:illustrationModel4"></span>
<img src="img/binomialProcess.jpeg" alt="A schematic of the infection model." height="400" />
<p class="caption">Figure 9.3: A schematic of the infection model.</p>
</div>
<ul>
<li>Below are the PMFs for a <strong>binomial distribution</strong> with the parameters <span class="math inline">\(n={2,10}\)</span> and <span class="math inline">\(p={0.3, 0.7}\)</span>.</li>
<li>The value at every point <span class="math inline">\(k\)</span> represents the probability of <span class="math inline">\(k\)</span> successes out of <span class="math inline">\(n\)</span> attempts if the probability of a success on each trial is <span class="math inline">\(p\)</span>.</li>
</ul>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-137-1.png" width="672" /></p>
<ul>
<li>Examples of such processes are: flipping coins, looking at shirts in a store, yes/no acceptability judgements, searching a corpus, lending money, …</li>
<li>Numbers generated by a mechanism that fits this description will will be distributed binomially (<span class="math inline">\(X \sim B(n, k)\)</span>).</li>
<li>There is an equation for the PMF, but to us it’s simply <code>dbinom(..., n, p)</code>, <code>pbinom()</code> and <code>rbinom(...)</code>.</li>
</ul>
<div id="gaussian-distribution-normal-distribution" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Gaussian Distribution (‘Normal Distribution’)</h3>
<ul>
<li>Generative process assumed by the <strong>gassian distribution</strong>: it is limiting case of a <em>‘substantial’</em> number of factors contributing to an outcome positively or negatively.</li>
<li>Think about the generative process roughly as below:</li>
</ul>
<div class="figure"><span id="fig:illustrationModel5"></span>
<img src="img/normalProcess.jpeg" alt="A schematic of the infection model." height="600" />
<p class="caption">Figure 9.4: A schematic of the infection model.</p>
</div>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-138-1.png" width="672" /></p>
<ul>
<li>There is an equation for the PDF, but to us it’s simply <code>dnorm(..., n, p)</code>, <code>pnorm()</code> and <code>rnorm(...)</code>.</li>
</ul>
</div>
</div>
<div id="a-likelihood-function-for-the-vaccine-data" class="section level2">
<h2><span class="header-section-number">9.3</span> A likelihood function for the vaccine data</h2>
<table>
<thead>
<tr class="header">
<th align="left">country</th>
<th align="left">group</th>
<th align="left">total participants</th>
<th align="left">COVID-19 cases</th>
<th align="left">[log-]likelihood</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Brazil</td>
<td align="left">placebo</td>
<td align="left">~6500</td>
<td align="left">167</td>
<td align="left">dbinom(167, 6500, <span class="math inline">\(p_{1B}\)</span>[, log=T])</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">vaccine</td>
<td align="left">~6500</td>
<td align="left">85</td>
<td align="left">dbinom(85, 6500, <span class="math inline">\(p_{2B}\)</span>[, log=T])</td>
</tr>
<tr class="odd">
<td align="left">Turkey</td>
<td align="left">placebo</td>
<td align="left">570</td>
<td align="left">26</td>
<td align="left">dbinom(26, 570, <span class="math inline">\(p_{1T}\)</span>[, log=T])</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">vaccine</td>
<td align="left">752</td>
<td align="left">3</td>
<td align="left">dbinom(3, 752, <span class="math inline">\(p_{2T}\)</span>[, log=T])</td>
</tr>
</tbody>
</table>
<ul>
<li>OK. So let’s write one log-likelihood function for the Brazil trial, and one for the Turkey trial and plot the log-likelihood as a function of the parameters <span class="math inline">\(p_{1B,T}\)</span> and <span class="math inline">\(p_{2B,T}\)</span>.</li>
</ul>
</div>
<div id="bayesian-inference-i" class="section level2">
<h2><span class="header-section-number">9.4</span> Bayesian Inference I</h2>
<ul>
<li>Now we know the relative likelihood of the data under different parameters <span class="math inline">\(\theta\)</span> (in our case: <span class="math inline">\(p_1, p_2\)</span>), i.e., <span class="math inline">\(P(D|\theta)\)</span>. [Think of <span class="math inline">\(\theta\)</span> as something of a <em>pronoun for parameters</em>.]</li>
<li>But I want to know the relative likelihood of the parameters given the data <span class="math inline">\(P(\theta|D)\)</span>.</li>
<li>According to the definition of conditional probability, we know two things to be true:
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(H|D) = P(H, D) / P(D)\)</span><br />
<span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(P(H|D) \cdot P(D) = P(H, D)\)</span></li>
<li><span class="math inline">\(P(D|H) = P(D, H) / P(H)\)</span><br />
<span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(P(D|H) \cdot P(H) = P(D, H)\)</span></li>
</ol></li>
<li>Because <span class="math inline">\(P(H, D)\)</span> and <span class="math inline">\(P(H, D)\)</span> are the same thing (the joint probability of <span class="math inline">\(H\)</span> and <span class="math inline">\(D\)</span>), the left sides of the above equations in brackets are also equal:<br />

<ul>
<li><span class="math inline">\(P(H|D) \cdot P(D) = P(D|H) \cdot P(H)\)</span><br />
<span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(P(H|D) = \frac{ P(D|H) \cdot P(H) }{P(D)}\)</span></li>
</ul></li>
<li>The result we just obtained is known as the <strong>Bayes Theorem</strong>:
<span class="math display">\[P(H|D) = \frac{ P(D|H) \cdot P(H) }{P(D)}\]</span>
<ul>
<li>P(H|D): probability of a hypothesis after seeing the data, or the <strong>posterior probability</strong> of the hypothesis.</li>
<li>P(D|H): probability of seeing such data under that hypothesis, or the <strong>likelihood</strong> of the data under the hypothesis.</li>
<li>P(H): probability of the hypothesis being true, or the <strong>prior probability</strong> of the hypothesis.</li>
<li>P(D): probability of seeing such data under any hypothesis, or the <strong>marginal probability of the data</strong>.</li>
</ul></li>
<li>In other words:
<span class="math display">\[Posterior~prob. = \frac{ Likelihood \cdot Prior~prob. }{Marginal~prob.~of~the~data}\]</span></li>
</ul>
</div>
<div id="returning-to-example-1" class="section level2">
<h2><span class="header-section-number">9.5</span> Returning to Example 1</h2>
<ul>
<li>Let’s use only the placebo arm of the Brazil trial, i.e., <em>‘167 events on ~6500 trials’</em> to estimate a <em>plausible range for the incidence</em> in similar groups, under similar conditions.<br />
</li>
<li>We know that the parameter <span class="math inline">\(p_{1B}\)</span> is probably somewhere in the vicinity of the incidence rate (i.e., <span class="math inline">\(0.026\)</span>). The question is, how close a vicinity?</li>
<li>We’ll use the Bayes Theorem:</li>
</ul>
<div id="likelihood" class="section level3">
<h3><span class="header-section-number">9.5.1</span> Likelihood</h3>
<ul>
<li>Let’s use only the placebo group of the Brazil data and assume that we have only five possibly hypotheses:
<ul>
<li><span class="math inline">\(H_1\)</span>:<span class="math inline">\(~p_1=0.020\)</span></li>
<li><span class="math inline">\(H_2\)</span>:<span class="math inline">\(~p_1=0.025\)</span></li>
<li><span class="math inline">\(H_3\)</span>:<span class="math inline">\(~p_1=0.030\)</span></li>
<li><span class="math inline">\(H_4\)</span>:<span class="math inline">\(~p_1=0.035\)</span></li>
<li><span class="math inline">\(H_5\)</span>:<span class="math inline">\(~p_1=0.040\)</span></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb119-1" title="1">p1B &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">02</span>, <span class="fl">.025</span>, <span class="fl">.03</span>, <span class="fl">.035</span>, <span class="fl">.04</span>)</a></code></pre></div>
<ul>
<li>Let’s compute <span class="math inline">\(P(D|H)\)</span>, <em>the likelihood of the data under each hypothesis.</em> We know how to do it, just use <code>dbinom</code>.</li>
</ul>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" title="1">(likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dt">x=</span><span class="dv">167</span>, <span class="dt">size=</span><span class="dv">6500</span>, <span class="dt">prob=</span>p1B))</a></code></pre></div>
<pre><code>## [1] 2.249124e-04 2.934130e-02 3.547394e-03 3.281750e-06 8.184725e-11</code></pre>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-142-1.png" width="672" /></p>
</div>
<div id="prior" class="section level3">
<h3><span class="header-section-number">9.5.2</span> Prior</h3>
<ul>
<li>Now what do we do about the prior? I have no idea. So let’s use what is called a <strong>flat prior</strong>: All hypotheses seem equally likely <em>a-priori</em>. Since there are 5 hypotheses, we therefore assign each hypothesis a probability of <span class="math inline">\(1/5\)</span>.</li>
</ul>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" title="1">(prior_p1B &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">5</span>, <span class="dv">5</span>))</a></code></pre></div>
<pre><code>## [1] 0.2 0.2 0.2 0.2 0.2</code></pre>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-144-1.png" width="672" /></p>
</div>
<div id="marginal-probability-of-the-data" class="section level3">
<h3><span class="header-section-number">9.5.3</span> Marginal probability of the data</h3>
<ul>
<li>So what is this <em>marginal probability of the data</em>? That is, the <em>average</em> probability of the data, i.e., under all possible hypotheses (weighted by their prior probability).</li>
</ul>
<p><span class="math display">\[ P(D) = \sum_{i} P(D|H_i) \cdot P(H_i) \]</span>
- <em>Please note that it’s the sum of the expressions in the numerator</em>.</p>
<ul>
<li>If the concept seems very alien to you, it may be based on the misconception that it’s a <em>‘real probability’</em>, i.e., something that exists in the real world.</li>
<li>However, it is model-based construct. That is, under the kind of model we assume generated the data, what is the probability of such data?</li>
<li>Another way to think about <span class="math inline">\(P(D)\)</span> is that it’s simply a <em>‘normalizing constant’</em>. Its purpose it to make sure that the probabilities add up to 1.</li>
</ul>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" title="1">(marginal_prob_data &lt;-<span class="st"> </span><span class="kw">sum</span>(likelihood <span class="op">*</span><span class="st"> </span>prior_p1B))</a></code></pre></div>
<pre><code>## [1] 0.006623378</code></pre>
</div>
<div id="posterior-probability" class="section level3">
<h3><span class="header-section-number">9.5.4</span> Posterior probability</h3>
<ul>
<li>Remember, <span class="math display">\[Posterior~probability_{(H_i)} = \frac{ Likelihood_{(H_i)} \cdot Prior~probability_{(H_i)} }{Marginal~prob.~of~the~data}\]</span></li>
<li>Let’s use that to compute the posterior probability of our hypotheses.</li>
</ul>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" title="1">posterior_p1B &lt;-<span class="st"> </span>(likelihood <span class="op">*</span><span class="st"> </span>prior_p1B) <span class="op">/</span><span class="st"> </span>marginal_prob_data</a></code></pre></div>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-147-1.png" width="672" /></p>
</div>
<div id="and-now-again-for" class="section level3">
<h3><span class="header-section-number">9.5.5</span> And now again, for</h3>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb127-1" title="1">p1B &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.015</span>, <span class="fl">0.040</span>, <span class="fl">.001</span>) <span class="co"># hypotheses</span></a>
<a class="sourceLine" id="cb127-2" title="2">likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dt">x=</span><span class="dv">167</span>, <span class="dt">size=</span><span class="dv">6500</span>, <span class="dt">prob=</span>p1B) <span class="co"># likelihood</span></a>
<a class="sourceLine" id="cb127-3" title="3">prior_p1B &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">/</span><span class="kw">length</span>(p1B), <span class="kw">length</span>(p1B)) <span class="co"># posterior</span></a>
<a class="sourceLine" id="cb127-4" title="4">marginal_prob_data &lt;-<span class="st"> </span><span class="kw">sum</span>(likelihood <span class="op">*</span><span class="st"> </span>prior_p1B) <span class="co"># marginal prob of data</span></a>
<a class="sourceLine" id="cb127-5" title="5">posterior_p1B &lt;-<span class="st"> </span>(likelihood <span class="op">*</span><span class="st"> </span>prior_p1B) <span class="op">/</span><span class="st"> </span>marginal_prob_data <span class="co"># posterior for p1B </span></a></code></pre></div>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" title="1"><span class="kw">ggplot</span>(<span class="dt">data=</span><span class="ot">NULL</span>, <span class="kw">aes</span>(<span class="dt">x=</span>p1B, <span class="dt">y=</span>posterior_p1B)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>() <span class="co">#+ scale_x_continuous(limits=c(0,.1))</span></a></code></pre></div>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-149-1.png" width="672" /></p>
</div>
</div>
<div id="bayesian-inference-ii" class="section level2">
<h2><span class="header-section-number">9.6</span> Bayesian Inference II</h2>
<ul>
<li>Luckily, we don’t have to do this every time. We can perform Bayesian with the R packages <em>brms</em>/<em>rstan</em>.</li>
<li>In contrast to what we did above, though, we don’t get back a plot, but a number of <em>samples from the posterior distribution</em>.</li>
<li>Let’s take a look at how it works:</li>
</ul>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb129-1" title="1"><span class="co"># load brms (you&#39;ll need to install &#39;brms&#39;, &#39;rstan&#39;, and possibly Rtools, depending on the system)</span></a>
<a class="sourceLine" id="cb129-2" title="2"><span class="kw">library</span>(brms)</a>
<a class="sourceLine" id="cb129-3" title="3"> </a>
<a class="sourceLine" id="cb129-4" title="4"><span class="co"># define data frame</span></a>
<a class="sourceLine" id="cb129-5" title="5">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">n_yes=</span><span class="dv">167</span>, <span class="dt">n=</span><span class="dv">6500</span>)</a>
<a class="sourceLine" id="cb129-6" title="6"></a>
<a class="sourceLine" id="cb129-7" title="7"><span class="co"># fit brms model</span></a>
<a class="sourceLine" id="cb129-8" title="8">m1 &lt;-<span class="st"> </span><span class="kw">brm</span>(n_yes<span class="op">|</span><span class="kw">trials</span>(n) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="co"># model specification </span></a>
<a class="sourceLine" id="cb129-9" title="9">          <span class="dt">data =</span> df, <span class="co"># data</span></a>
<a class="sourceLine" id="cb129-10" title="10">          <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="st">&quot;identity&quot;</span>), <span class="co"># assume that the outcome is binomially distributed</span></a>
<a class="sourceLine" id="cb129-11" title="11">          <span class="dt">cores =</span> <span class="dv">4</span>, <span class="co"># use 4 cores</span></a>
<a class="sourceLine" id="cb129-12" title="12">          <span class="dt">file =</span> <span class="st">&quot;./models/model1&quot;</span> <span class="co"># save to file (</span><span class="al">WARNING</span><span class="co">: if file exists, model won&#39;t be fitted again even if it changed)</span></a>
<a class="sourceLine" id="cb129-13" title="13">          ) </a>
<a class="sourceLine" id="cb129-14" title="14"><span class="kw">summary</span>(m1)</a></code></pre></div>
<pre><code>##  Family: binomial 
##   Links: mu = identity 
## Formula: n_yes | trials(n) ~ 1 
##    Data: df (Number of observations: 1) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.03      0.00     0.02     0.03 1.00     1458     1719
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<ul>
<li>As you see, the model …
<ul>
<li>… provides coefficient <em>estimates</em> in the <code>Estimate</code> column under <code>Population-Level Effects</code> (estimate = <span class="math inline">\(0.03\)</span>; rounded).</li>
<li>… provides <em>credible intervals</em> (95%) in the <code>l-95% CI</code>, and <code>u-95% CI</code> columns under <code>Population-Level Effects</code> (<span class="math inline">\(CrI = [0.02; 0.03]\)</span>).</li>
<li>The most important result is the <em>95% credible interval</em> (usually <em>‘CrI’</em>, sometimes <em>‘CI’</em>). Our model tells us that with 95% probability, the parameter is in this range.</li>
</ul></li>
<li></li>
</ul>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb131-1" title="1"><span class="co"># extract samples from the model and take a look at them</span></a>
<a class="sourceLine" id="cb131-2" title="2">samples1 &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(m1)</a>
<a class="sourceLine" id="cb131-3" title="3"><span class="kw">head</span>(samples1, <span class="dv">5</span>)</a></code></pre></div>
<pre><code>##   b_Intercept      lp__
## 1  0.02728792 -20.31070
## 2  0.02728792 -20.31070
## 3  0.02182273 -22.15158
## 4  0.02572990 -19.99310
## 5  0.02499430 -20.05733</code></pre>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb133-1" title="1"><span class="co"># compute exact credible interval</span></a>
<a class="sourceLine" id="cb133-2" title="2">(cri95 &lt;-<span class="st"> </span>HDInterval<span class="op">::</span><span class="kw">hdi</span>(samples1<span class="op">$</span>b_Intercept))</a></code></pre></div>
<pre><code>##      lower      upper 
## 0.02217407 0.02998686 
## attr(,&quot;credMass&quot;)
## [1] 0.95</code></pre>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb135-1" title="1"><span class="co"># plot the samples histogram ...</span></a>
<a class="sourceLine" id="cb135-2" title="2">p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(samples1, <span class="kw">aes</span>(b_Intercept)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">breaks=</span><span class="kw">c</span>(p1B<span class="fl">-.001</span><span class="op">/</span><span class="dv">2</span>,<span class="fl">0.040+.001</span>) )</a>
<a class="sourceLine" id="cb135-3" title="3"><span class="co"># ... anong with our old approximation ...</span></a>
<a class="sourceLine" id="cb135-4" title="4">p &lt;-<span class="st"> </span>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">data=</span><span class="kw">data.frame</span>(p1B, posterior_p1B), <span class="kw">aes</span>(<span class="dt">x=</span>p1B, <span class="dt">y=</span>posterior_p1B<span class="op">*</span><span class="dv">4000</span>), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb135-5" title="5"><span class="st">          </span><span class="kw">geom_line</span>(<span class="dt">data=</span><span class="kw">data.frame</span>(p1B, posterior_p1B), <span class="kw">aes</span>(<span class="dt">x=</span>p1B, <span class="dt">y=</span>posterior_p1B<span class="op">*</span><span class="dv">4000</span>), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb135-6" title="6"><span class="co"># ... and the 95% CrI</span></a>
<a class="sourceLine" id="cb135-7" title="7">p <span class="op">+</span><span class="st"> </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> cri95[<span class="st">&#39;lower&#39;</span>], <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> cri95[<span class="st">&#39;upper&#39;</span>], <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>)</a></code></pre></div>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-151-1.png" width="672" /></p>
</div>
<div id="back-to-our-incidence-rates" class="section level2">
<h2><span class="header-section-number">9.7</span> Back to our incidence rates</h2>
<div id="brazil" class="section level3">
<h3><span class="header-section-number">9.7.1</span> Brazil</h3>
<ul>
<li>Estimate a model under the assumption that <span class="math inline">\(p = a + b \cdot c\_is\_vaccine\)</span>, where c_is_vaccine is a centered predictor.
<ul>
<li><em>Intercept:</em> <span class="math inline">\(a\)</span> is the average incidence</li>
<li><em>Slope:</em> <span class="math inline">\(b\)</span> is the difference between <span class="math inline">\(p_{1B}\)</span> and <span class="math inline">\(p_{1T}\)</span></li>
<li>Remember, the model will return samples that represent the posterior probability distribution over the <em>parameters</em> <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, not the <em>samples</em>!</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb136-1" title="1"><span class="co"># define data frame</span></a>
<a class="sourceLine" id="cb136-2" title="2">df2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">n_yes =</span> <span class="kw">c</span>(<span class="dv">167</span>, <span class="dv">85</span>), </a>
<a class="sourceLine" id="cb136-3" title="3">                  <span class="dt">n =</span> <span class="kw">c</span>(<span class="dv">6500</span>, <span class="dv">6500</span>),</a>
<a class="sourceLine" id="cb136-4" title="4">                  <span class="dt">c_is_vaccine =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb136-5" title="5">                  )</a>
<a class="sourceLine" id="cb136-6" title="6"></a>
<a class="sourceLine" id="cb136-7" title="7"><span class="co"># fit brms model</span></a>
<a class="sourceLine" id="cb136-8" title="8">m2 &lt;-<span class="st"> </span><span class="kw">brm</span>(n_yes<span class="op">|</span><span class="kw">trials</span>(n) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>c_is_vaccine, <span class="co"># model specification </span></a>
<a class="sourceLine" id="cb136-9" title="9">          <span class="dt">data =</span> df2, <span class="co"># data</span></a>
<a class="sourceLine" id="cb136-10" title="10">          <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="st">&quot;identity&quot;</span>), <span class="co"># assume that the outcome is binomially distributed</span></a>
<a class="sourceLine" id="cb136-11" title="11">          <span class="dt">cores =</span> <span class="dv">4</span>, <span class="co"># use 4 cores</span></a>
<a class="sourceLine" id="cb136-12" title="12">          <span class="dt">file =</span> <span class="st">&quot;./models/model2&quot;</span> <span class="co"># save to file (</span><span class="al">WARNING</span><span class="co">: if file exists, model won&#39;t be fitted again even if it changed)</span></a>
<a class="sourceLine" id="cb136-13" title="13">          ) </a>
<a class="sourceLine" id="cb136-14" title="14"><span class="kw">summary</span>(m2)</a></code></pre></div>
<pre><code>##  Family: binomial 
##   Links: mu = identity 
## Formula: n_yes | trials(n) ~ 1 + c_is_vaccine 
##    Data: df2 (Number of observations: 2) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept        0.02      0.00     0.02     0.02 1.00     2462     2378
## c_is_vaccine    -0.01      0.00    -0.02    -0.01 1.00     1395     1502
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb138-1" title="1">samples2 &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(m2)</a>
<a class="sourceLine" id="cb138-2" title="2"><span class="kw">head</span>(samples2, <span class="dv">5</span>)</a></code></pre></div>
<pre><code>##   b_Intercept b_c_is_vaccine      lp__
## 1  0.02008888   -0.009867631 -14.53036
## 2  0.01943221   -0.012430289 -13.49045
## 3  0.02058865   -0.014269747 -14.03007
## 4  0.02052979   -0.015209252 -14.22080
## 5  0.01968251   -0.011715166 -13.62410</code></pre>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb140-1" title="1"><span class="co"># apply the reverse logic of the linear model to get posterior distributions for p1B and p2B from the infection model above</span></a>
<a class="sourceLine" id="cb140-2" title="2">samples_p1B &lt;-<span class="st">  </span>samples2<span class="op">$</span>b_Intercept <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span><span class="st"> </span>samples2<span class="op">$</span>b_c_is_vaccine</a>
<a class="sourceLine" id="cb140-3" title="3">samples_p2B &lt;-<span class="st">  </span>samples2<span class="op">$</span>b_Intercept <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span><span class="st"> </span>samples2<span class="op">$</span>b_c_is_vaccine</a>
<a class="sourceLine" id="cb140-4" title="4"></a>
<a class="sourceLine" id="cb140-5" title="5"><span class="co"># use these samples to compute the posterior distribution of efficacy</span></a>
<a class="sourceLine" id="cb140-6" title="6">samples_eff_Brazil &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>samples_p2B<span class="op">/</span>samples_p1B</a>
<a class="sourceLine" id="cb140-7" title="7"></a>
<a class="sourceLine" id="cb140-8" title="8"><span class="co"># compute exact credible interval</span></a>
<a class="sourceLine" id="cb140-9" title="9">(cri95_eff_Brazil &lt;-<span class="st"> </span>HDInterval<span class="op">::</span><span class="kw">hdi</span>(samples_eff_Brazil))</a></code></pre></div>
<pre><code>##     lower     upper 
## 0.3494192 0.6147580 
## attr(,&quot;credMass&quot;)
## [1] 0.95</code></pre>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb142-1" title="1"><span class="co"># plot the samples histogram ...</span></a>
<a class="sourceLine" id="cb142-2" title="2">p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span><span class="ot">NULL</span>, <span class="kw">aes</span>(samples_eff_Brazil)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins=</span><span class="dv">50</span>)</a>
<a class="sourceLine" id="cb142-3" title="3"><span class="co"># ... and the 95% CrI</span></a>
<a class="sourceLine" id="cb142-4" title="4">p <span class="op">+</span><span class="st"> </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> cri95_eff_Brazil[<span class="st">&#39;lower&#39;</span>], <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> cri95_eff_Brazil[<span class="st">&#39;upper&#39;</span>], <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>)</a></code></pre></div>
<p><img src="LectureNotes_files/figure-html/unnamed-chunk-153-1.png" width="672" /></p>
</div>
<div id="turkey" class="section level3">
<h3><span class="header-section-number">9.7.2</span> Turkey</h3>
<ul>
<li>Now let’s do the same for the Turkey trial …</li>
</ul>
<!--
- This means that: 
  $$P(H_{BS}|D) = \frac{ P(D|H_{BS}) \cdot P(H_{BS}) }{P(D)}$$, and $$P(H_{NBS}|D) = \frac{ P(D|H_{NBS}) \cdot P(H_{NBS}) }{P(D)}$$

- How do we compute the numbers in $P(H_{BS}|D) = \frac{ P(D|H_{BS}) \cdot P(H_{BS}) }{P(D)}$ and $P(H_{NBS}|D) = \frac{ P(D|H_{NBS}) \cdot P(H_{NBS}) }{P(D)}$
  
  
- **Likelihood:** Computing $P(D|H)$ is straightforward, given a reasonable statistical model of the data-generating process. In our case, it's `dbinom(8, 10, .75)` and `dbinom(8, 10, .5)`.
- **Prior:** The prior is supposed to encode the analyst's prior belief, based on previously seen data and domain knowledge. Let's use $0.5$ for both.
-->

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="statistical-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="case-studies.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["LectureNotes.pdf", "LectureNotes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
